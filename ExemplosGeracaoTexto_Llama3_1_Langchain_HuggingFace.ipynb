{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_Llama3_1/blob/master/ExemplosGeracaoTexto_Llama3_1_Langchain_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "# Exemplo de Geração de textos usando Llama v3.1 8B 8bit usando Langchain e Transformers by HuggingFace\n",
        "\n",
        "Exemplo de uso do modelo de linguagem grande Llama v2.0.\n",
        "- Análise da geração de textos\n",
        "- Prompts com textos emparelhados\n",
        "- Injentando padrões no prompt\n",
        "- Padrão Persona\n",
        "- Verificação cognitiva\n",
        "- Pensamento em cadeia\n",
        "- Refinamento de perguntas\n",
        "\n",
        "**Toda a execução ocorre no Google Colaboratory.**\n",
        "\n",
        "Pré-requisitos:\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "- Configurar o notebook para usar GPU- Acesse o menu 'Ambiente de Execução -> Alterar o tipo do ambiente de execução -> Acelerador de hardware -> T4 GPU\n",
        "\n",
        "\n",
        "**Referências**\n",
        "https://medium.com/the-techlife/using-huggingface-openai-and-cohere-models-with-langchain-db57af14ac5b\n",
        "\n",
        "\n",
        "**Notebook de referência:**\n",
        "\n",
        "https://github.com/guardiaum/tutorial-sbbd2023/blob/main/Prompt_Engineering.ipynb\n",
        "\n",
        "\n",
        "**Lista dos modelos:**\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "\n",
        "**Artigos referências:**\n",
        "\n",
        "https://dev.to/nithinibhandari1999/how-to-run-llama-2-on-your-local-computer-42g1\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_O5mNHKt2oW"
      },
      "source": [
        "## Data e hora de execução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpNBAbS1t5Xu",
        "outputId": "befb4629-96be-4151-b785-4960dd2ec245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data e hora da execução do programa: 21/09/2024 14:17:34\n"
          ]
        }
      ],
      "source": [
        "# Biblioteca de date\n",
        "from datetime import datetime\n",
        "\n",
        "data_e_hora_atuais = datetime.now()\n",
        "data_e_hora_em_texto = data_e_hora_atuais.strftime('%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "print(\"Data e hora da execução do programa:\", data_e_hora_em_texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "## Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "outputs": [],
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "## Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "outputs": [],
      "source": [
        "# Biblioteca do sistema\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-xSroBtxPL2"
      },
      "source": [
        "## Versão Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xu2haQbxRTc",
        "outputId": "0ef6f183-21f8-4108-e0e0-814b88f072f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versão Python: 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "# Biblioteca do sistema\n",
        "import sys\n",
        "\n",
        "print(\"Versão Python:\", sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZrNxBGQdMrM"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0qbx-9EdMxS",
        "outputId": "0f4116aa-337f-4d65-923f-e8bf7733cea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU está disponível.\n"
          ]
        }
      ],
      "source": [
        "# Import de biblioteca\n",
        "import torch\n",
        "\n",
        "GPU_ENABLE = torch.cuda.is_available()\n",
        "\n",
        "if GPU_ENABLE:\n",
        "    print(\"GPU está disponível.\")\n",
        "else:\n",
        "    print(\"GPU não está disponível.\")\n",
        "\n",
        "device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqGFZwtQ1iz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4W0lRM4Q1Vl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmhxcvIfbG2"
      },
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603LYIYKBmq5"
      },
      "source": [
        "Função auxiliar para formatar o tempo como `hh: mm: ss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guy6B4whsZFR"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas.\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def formataTempo(tempo):\n",
        "    \"\"\"\n",
        "      Pega a tempo em segundos e retorna uma string hh:mm:ss\n",
        "    \"\"\"\n",
        "    # Arredonda para o segundo mais próximo.\n",
        "    tempo_arredondado = int(round((tempo)))\n",
        "\n",
        "    # Formata como hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=tempo_arredondado))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1vu-ch8yT5R"
      },
      "source": [
        "Imprime linhas menores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BKQZtF9yUBs"
      },
      "outputs": [],
      "source": [
        "def print_linhas_menores(texto, tamanho=120):\n",
        "  for i in range(0, len(texto), tamanho):\n",
        "    print(texto[i:i+tamanho])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "# 1 - Instalação das bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGrlTKgSLdNj"
      },
      "source": [
        "Bibioteca LangChain é um framework de código aberto para o desenvolvimento de aplicações usando modelos de linguagem grandes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppVeArJcLdVb",
        "outputId": "3fad8326-8041-49a9-ec15-31594b82593a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community==0.3.0\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.0) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.0) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.3.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.0 (from langchain_community==0.3.0)\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain_community==0.3.0)\n",
            "  Downloading langchain_core-0.3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.112 (from langchain_community==0.3.0)\n",
            "  Downloading langsmith-0.1.125-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.0) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community==0.3.0)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community==0.3.0) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain_community==0.3.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.0) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.0) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.0) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.0)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.0->langchain_community==0.3.0)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain_community==0.3.0) (2.9.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain_community==0.3.0)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community==0.3.0) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community==0.3.0) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.112->langchain_community==0.3.0)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.112->langchain_community==0.3.0)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.0)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.3.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community==0.3.0) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.3.0) (3.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community==0.3.0) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community==0.3.0)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community==0.3.0) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community==0.3.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_community==0.3.0)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community==0.3.0) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community==0.3.0) (1.2.2)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.5-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.125-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, python-dotenv, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-core-0.3.5 langchain-text-splitters-0.3.0 langchain_community-0.3.0 langsmith-0.1.125 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 tenacity-8.5.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community==0.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFmOuwOY2GmC",
        "outputId": "5f21d078-5fb4-4d61-b6f6-646139ba5fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-huggingface==0.1.0\n",
            "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.1.0) (0.24.7)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.1.0) (0.3.5)\n",
            "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface==0.1.0)\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.1.0) (0.19.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.1.0) (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (0.1.125)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (8.5.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (10.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface==0.1.0) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface==0.1.0) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.1.0) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (3.1.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-huggingface==0.1.0) (1.2.2)\n",
            "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers, langchain-huggingface\n",
            "Successfully installed langchain-huggingface-0.1.0 sentence-transformers-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-huggingface==0.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0jVfo3QM3h"
      },
      "source": [
        "O bitsandbytes é um wrapper leve em torno de funções personalizadas CUDA, em particular otimizadores de 8 bits, multiplicação de matrizes (LLM.int8()) e funções de quantização. É uma dependência do accelerate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12GE2W3fQM_n",
        "outputId": "2a26aa6f-527c-45bc-d388-3f2868808b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes==0.43.3\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.3) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.3) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.3) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes==0.43.3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes==0.43.3) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes==0.43.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wU6vuyAuPd"
      },
      "source": [
        "Accelerate é uma biblioteca que permite que o mesmo código PyTorch seja executado em qualquer configuração distribuída adicionando apenas quatro linhas de código. Otimiza as operações do PyTorch, especialmente na GPU.\n",
        "\n",
        "https://pypi.org/project/accelerate/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTMID1rZAvx7",
        "outputId": "93c0e002-23dd-44e8-c1be-962b4001c48a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (2.4.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.2) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.2) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.2) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.34.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.34.2) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.34.2) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.34.2) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.34.2) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate==0.34.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "A Biblioteca A Biblioteca Transformers fornece APIs e ferramentas para baixar e treinar facilmente modelos pré-treinados de última geração para Processamento de linguagem natural, Visão computacional, Áudio, etc.\n",
        "\n",
        "Fornece uma maneira direta de usar modelos pré-treinados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RfUN_KolV-f",
        "outputId": "ba161ac5-c554-4d6f-d8a2-158fcbf15229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.44.2 in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.44.2) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers==4.44.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlrWrRP02tuZ"
      },
      "source": [
        "A Biblioteca huggingface-cli fornece vários comandos para interagir com o Hugging Face Hub a partir da linha de comando. Um desses comandos é o login, que permite aos usuários se autenticarem no Hub usando suas credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQxtD3Zk14ov"
      },
      "outputs": [],
      "source": [
        "#!pip install huggingface-hub==0.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NdUAv1OyE7v"
      },
      "source": [
        "## Versão bibliotecas instaladas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffCAEnsNyG4G",
        "outputId": "b41f58e5-7cc6-4417-b5d3-b9f6f13e14bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==0.34.2\n",
            "aiohappyeyeballs==2.4.0\n",
            "aiohttp==3.10.5\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.16\n",
            "albucore==0.0.16\n",
            "albumentations==1.4.15\n",
            "altair==4.2.2\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.5.1\n",
            "arviz==0.19.0\n",
            "astropy==6.1.3\n",
            "astropy-iers-data==0.2024.9.16.0.32.21\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.1.0\n",
            "attrs==24.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.7.0\n",
            "babel==2.16.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bidict==0.23.1\n",
            "bigframes==1.17.0\n",
            "bigquery-magics==0.2.0\n",
            "bitsandbytes==0.43.3\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.4.3\n",
            "bqplot==0.12.43\n",
            "branca==0.7.2\n",
            "build==1.2.2\n",
            "CacheControl==0.14.0\n",
            "cachetools==5.5.0\n",
            "catalogue==2.0.10\n",
            "certifi==2024.8.30\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.2\n",
            "chex==0.1.86\n",
            "clarabel==0.9.0\n",
            "click==8.1.7\n",
            "cloudpathlib==0.19.0\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.30.3\n",
            "cmdstanpy==1.2.4\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.3.0\n",
            "cryptography==43.0.1\n",
            "cuda-python==12.2.1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl#sha256=57366e7ef09dc63e0b389aff20df6c37d91e2790065861ee31a4720149f5b694\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.5.3\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.11\n",
            "dask==2024.8.0\n",
            "dataclasses-json==0.6.7\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.3.0\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "distributed==2024.8.0\n",
            "distro==1.7.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docstring_parser==0.16\n",
            "docutils==0.18.1\n",
            "dopamine_rl==4.0.9\n",
            "duckdb==1.1.0\n",
            "earthengine-api==1.0.0\n",
            "easydict==1.13\n",
            "ecos==2.0.14\n",
            "editdistance==0.8.1\n",
            "eerepr==0.0.4\n",
            "einops==0.8.0\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.9.4\n",
            "etuples==0.3.9\n",
            "eval_type_backport==0.2.0\n",
            "exceptiongroup==1.2.2\n",
            "fastai==2.7.17\n",
            "fastcore==1.7.8\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.20.0\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.16.1\n",
            "firebase-admin==6.5.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==24.3.25\n",
            "flax==0.8.4\n",
            "folium==0.17.0\n",
            "fonttools==4.53.1\n",
            "frozendict==2.4.4\n",
            "frozenlist==1.4.1\n",
            "fsspec==2024.6.1\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2024.6.1\n",
            "GDAL==3.6.4\n",
            "gdown==5.1.0\n",
            "geemap==0.34.2\n",
            "gensim==4.3.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.0.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.6\n",
            "google-api-core==2.19.2\n",
            "google-api-python-client==2.137.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.1\n",
            "google-cloud-aiplatform==1.67.0\n",
            "google-cloud-bigquery==3.25.0\n",
            "google-cloud-bigquery-connection==1.15.5\n",
            "google-cloud-bigquery-storage==2.26.0\n",
            "google-cloud-bigtable==2.26.0\n",
            "google-cloud-core==2.4.1\n",
            "google-cloud-datastore==2.19.0\n",
            "google-cloud-firestore==2.16.1\n",
            "google-cloud-functions==1.16.5\n",
            "google-cloud-iam==2.15.2\n",
            "google-cloud-language==2.13.4\n",
            "google-cloud-pubsub==2.23.1\n",
            "google-cloud-resource-manager==1.12.5\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.15.5\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz#sha256=7e35cc419691f39f18d9e9b7abf55d090f62540b4838cf5516fd4487590e1449\n",
            "google-crc32c==1.6.0\n",
            "google-generativeai==0.7.2\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.65.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.3\n",
            "greenlet==3.1.0\n",
            "grpc-google-iam-v1==0.13.1\n",
            "grpcio==1.64.1\n",
            "grpcio-status==1.48.2\n",
            "gspread==6.0.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h11==0.14.0\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.11.0\n",
            "holidays==0.57\n",
            "holoviews==1.19.1\n",
            "html5lib==1.1\n",
            "httpcore==1.0.5\n",
            "httpimport==1.4.0\n",
            "httplib2==0.22.0\n",
            "httpx==0.27.2\n",
            "huggingface-hub==0.24.7\n",
            "humanize==4.10.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==8.0.0\n",
            "idna==3.10\n",
            "imageio==2.35.1\n",
            "imageio-ffmpeg==0.5.1\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.12.3\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.0\n",
            "importlib_metadata==8.5.0\n",
            "importlib_resources==6.4.5\n",
            "imutils==0.5.4\n",
            "inflect==7.4.0\n",
            "iniconfig==2.0.0\n",
            "intel-cmplr-lib-ur==2024.2.1\n",
            "intel-openmp==2024.2.1\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.19.2\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.26\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.26+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=813cf1fe3e7ca4dbf5327d6e7b4fc8521e92d8bba073ee645ae0d5d036a25750\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.1.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.4\n",
            "joblib==1.4.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==3.3.0\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.23.0\n",
            "jsonschema-specifications==2023.12.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.19.2\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.13\n",
            "kaggle==1.6.17\n",
            "kagglehub==0.2.9\n",
            "keras==3.4.1\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.7\n",
            "langchain==0.3.0\n",
            "langchain-community==0.3.0\n",
            "langchain-core==0.3.5\n",
            "langchain-huggingface==0.1.0\n",
            "langchain-text-splitters==0.3.0\n",
            "langcodes==3.4.0\n",
            "langsmith==0.1.125\n",
            "language_data==1.2.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.5.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.4\n",
            "marisa-trie==1.2.0\n",
            "Markdown==3.7\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "marshmallow==3.22.0\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.1\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.11.4\n",
            "mkl==2024.2.2\n",
            "ml-dtypes==0.4.1\n",
            "mlxtend==0.23.1\n",
            "more-itertools==10.5.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.8\n",
            "multidict==6.1.0\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "mypy-extensions==1.0.0\n",
            "namex==0.0.8\n",
            "natsort==8.4.0\n",
            "nbclassic==1.1.0\n",
            "nbclient==0.10.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.10.4\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.3\n",
            "nibabel==5.2.1\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numexpr==2.10.1\n",
            "numpy==1.26.4\n",
            "nvidia-nccl-cu12==2.23.4\n",
            "nvtx==0.2.10\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.10.0.84\n",
            "opencv-python==4.10.0.84\n",
            "opencv-python-headless==4.10.0.84\n",
            "openpyxl==3.1.5\n",
            "opt-einsum==3.3.0\n",
            "optax==0.2.2\n",
            "optree==0.12.1\n",
            "orbax-checkpoint==0.6.4\n",
            "orjson==3.10.7\n",
            "osqp==0.6.7.post0\n",
            "packaging==24.1\n",
            "pandas==2.1.4\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.23.1\n",
            "pandas-stubs==2.1.4.231227\n",
            "pandocfilters==1.5.1\n",
            "panel==1.4.5\n",
            "param==2.1.1\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.6\n",
            "peewee==3.17.6\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==10.4.0\n",
            "pip-tools==7.4.1\n",
            "platformdirs==4.3.6\n",
            "plotly==5.15.0\n",
            "plotnine==0.13.6\n",
            "pluggy==1.5.0\n",
            "polars==1.6.0\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "prefetch_generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.11.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.20.0\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.47\n",
            "prophet==1.1.5\n",
            "proto-plus==1.24.0\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==14.0.2\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.1\n",
            "pycocotools==2.0.8\n",
            "pycparser==2.22\n",
            "pydantic==2.9.2\n",
            "pydantic-settings==2.5.2\n",
            "pydantic_core==2.23.4\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==3.0.1\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.20.0\n",
            "pyerfa==2.0.1.4\n",
            "pygame==2.6.0\n",
            "Pygments==2.18.0\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.9.0\n",
            "pymc==5.16.2\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.3.0\n",
            "pyogrio==0.9.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.1.4\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.1.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.25.4\n",
            "pytest==7.4.4\n",
            "python-apt==2.4.0\n",
            "python-box==7.2.0\n",
            "python-dateutil==2.8.2\n",
            "python-dotenv==1.0.1\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.8.2\n",
            "pytz==2024.2\n",
            "pyviz_comms==3.0.3\n",
            "PyYAML==6.0.2\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post4\n",
            "ratelim==0.1.6\n",
            "referencing==0.35.1\n",
            "regex==2024.9.11\n",
            "requests==2.32.3\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.9.0\n",
            "rich==13.8.1\n",
            "rmm-cu12==24.4.0\n",
            "rpds-py==0.20.0\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.5\n",
            "scikit-image==0.23.2\n",
            "scikit-learn==1.3.2\n",
            "scipy==1.13.1\n",
            "scooby==0.10.0\n",
            "scs==3.2.7\n",
            "seaborn==0.13.1\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==3.1.1\n",
            "sentencepiece==0.1.99\n",
            "shapely==2.0.6\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.6\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==7.0.4\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.6\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.7.6\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.35\n",
            "sqlglot==20.11.0\n",
            "sqlparse==0.5.1\n",
            "srsly==2.4.8\n",
            "stanio==0.5.1\n",
            "statsmodels==0.14.3\n",
            "StrEnum==0.4.15\n",
            "sympy==1.13.2\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.13.1\n",
            "tblib==3.0.0\n",
            "tenacity==8.5.0\n",
            "tensorboard==2.17.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.17.0\n",
            "tensorflow-datasets==4.9.6\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.15.0\n",
            "tensorflow-probability==0.24.0\n",
            "tensorstore==0.1.65\n",
            "termcolor==2.4.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.17.0\n",
            "thinc==8.2.5\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2024.8.30\n",
            "tinycss2==1.3.0\n",
            "tokenizers==0.19.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121_full/torch-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=f3ed9a2b7f8671b2b32a2f036d1b81055eb3ad9b18ba43b705aa34bae4289e1a\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121_full/torchaudio-2.4.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=da8c87c80a1c1376a48dc33eef30b03bbdf1df25a05bd2b1c620b8811c7b19be\n",
            "torchsummary==1.5.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu121_full/torchvision-0.19.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=b8cc4bf381b75522995b601e07a1b433b5fd925dc3e34a7fa6cd22f449d65379\n",
            "tornado==6.3.3\n",
            "tqdm==4.66.5\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.44.2\n",
            "tweepy==4.14.0\n",
            "typeguard==4.3.0\n",
            "typer==0.12.5\n",
            "types-pytz==2024.2.0.20240913\n",
            "types-setuptools==75.1.0.20240917\n",
            "typing-inspect==0.9.0\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2024.1\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.8.0\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "Werkzeug==3.0.4\n",
            "widgetsnbextension==3.6.9\n",
            "wordcloud==1.9.3\n",
            "wrapt==1.16.0\n",
            "xarray==2024.9.0\n",
            "xarray-einstats==0.7.0\n",
            "xgboost==2.1.1\n",
            "xlrd==2.0.1\n",
            "xyzservices==2024.9.0\n",
            "yarl==1.11.1\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.43\n",
            "zict==3.0.0\n",
            "zipp==3.20.2\n"
          ]
        }
      ],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "# 2 - Carregando o LLM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFRSYoCArrQ-"
      },
      "source": [
        "## 2.1 - Login no huggingface\n",
        "\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "\n",
        "Insira o token quando solicitado e depois digite Y para adicionar as credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bkqIoNU18UH"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACJuj9wB9kjZ"
      },
      "source": [
        "Se o seu notebook não for público e não desejar incluir o **Access Token do HuggingFace** toda vez que for executar o notebook preencha a variável '\\<valor_do_acess_token\\>'.\n",
        "\n",
        "Se for público crie a variável 'HF_TOKEN' com o valor do **Access Token do HuggingFace**. Abra o Google Colab e navegue até a nova seção 'Secrets' na barra lateral e adicione a variável."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRVr7uqp9Ubk"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub.hf_api import HfFolder\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    ACCESS_TOKEN  = userdata.get('HF_TOKEN')\n",
        "\n",
        "    HfFolder.save_token(ACCESS_TOKEN)\n",
        "\n",
        "else:\n",
        "    ACCESS_TOKEN = \"<valor_do_acess_token>\"\n",
        "\n",
        "    HfFolder.save_token(ACCESS_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIzrrJLw9oQd"
      },
      "source": [
        "Mostrando o usuário conectado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLrSstlxR_kq"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niwUEmYM6kjG"
      },
      "source": [
        "## 2.2 - Nome do modelo de linguagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBOzL86X6kjM"
      },
      "source": [
        "Define o nome do modelo a ser carregado\n",
        "Lista dos modelos:\n",
        "  - https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct\n",
        "  https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zOnSymM6kjM"
      },
      "outputs": [],
      "source": [
        "nome_modelo = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "#nome_modelo = \"meta-llama/Meta-Llama-3.1-70B-Instruct\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzWcQNSORrYC"
      },
      "source": [
        "## 2.3 - Carrega o tokenizador\n",
        "\n",
        "Carregando o **tokenizador** da comunidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "f748db1fdb6b4e9395151414fcd1c4f3",
            "9289f5ec52ac4fed9aa3b8fda9b80550",
            "673a01456a984d4b8be16b76995ebaac",
            "45485fae1ab647caa2b1e4a86b9a443d",
            "64b3fcb488934fd4a41494655dc80189",
            "a6847f804eee43d1816208b9ccaffe93",
            "978c81ad0df44d4091329bd548a58042",
            "eb01f9b6aeb44e39ac844d79ebd15204",
            "9e1fed203cdb4af385fe473491ce0d0c",
            "485658f399484b999da8ef374dd7e67d",
            "40e5da2829654257969c12e77531e0ca",
            "b24403fae79f4694bdea1c8d60916219",
            "362ceaaff6784e2daeb2052d857e60a8",
            "20b272b8fbdd48de9e1744e729279e15",
            "2a92f2020cb2450a9352089fa32dd673",
            "40bc3d042386446cbf29f396af98c572",
            "9ecdfa95ef104502805b13840d05003e",
            "cfa6525ffad740e2a61717d8f33ffd3d",
            "68bfd77475c2445ba926220299931c4b",
            "9f398683517c4f59b15748b3fff194cd",
            "1dd620f9a61b41fd9b2fe8018c47e961",
            "e5aa7bc32fcc4d5db6b6acf9b69019e4",
            "8ed4d05ab7384154b2d3541dfbe96d9b",
            "cf77cdcdb7d04246b65f64445f1e698e",
            "1521bc93d8434043ba07ab76ade23821",
            "7b73ab6cda2f441592a7341fb2ae6f59",
            "618270ec33354abaad9db39832652874",
            "8a7b53202dfd49d688a09c24753270e4",
            "17d556116b9a49bfb957497dde86a956",
            "33269b9a764d417bac6f3287b906ed93",
            "67a49e8fb33b435d9b917b96d0474634",
            "45da03f78bf8438cb20551f12eec3522",
            "090811705a994611a7281cb7e23e5157"
          ]
        },
        "id": "MlSM1VufRw5B",
        "outputId": "d53d5e85-c6b2-4ba4-c397-e12900523ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregando o tokenizador meta-llama/Meta-Llama-3.1-8B-Instruct da comunidade...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f748db1fdb6b4e9395151414fcd1c4f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b24403fae79f4694bdea1c8d60916219",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ed4d05ab7384154b2d3541dfbe96d9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Importando as bibliotecas do Tokenizador\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Carregando o Tokenizador da comunidade\n",
        "print('Carregando o tokenizador ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNhZxBfM0LEe"
      },
      "source": [
        "Tamanho do vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzgbIOUI0LEf",
        "outputId": "227e7989-d028-42e4-8390-d6d425f999c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128256\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNMEhN9BHuc"
      },
      "source": [
        "## 2.4 - Carregando o LLM\n",
        "\n",
        "Carregando o **LLM** da comunidade HuggingFace.\n",
        "\n",
        "Parametrização do from_pretrained\n",
        "https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69JpPrGoUpML"
      },
      "source": [
        "Esvazia a memória"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjMLpZzwUpWC"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "def flush():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj6_jlk35AUI"
      },
      "source": [
        "### 2.4.1 - LLama 3.1 com 4 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kx5Ed64YlV-"
      },
      "outputs": [],
      "source": [
        "# # Importando as bibliotecas do Modelo\n",
        "# from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
        "# import torch\n",
        "# import time\n",
        "\n",
        "# # Guarda o tempo de início do carregamento do modelo\n",
        "# tempo_inicio = time.time()\n",
        "\n",
        "# # Carregando o Modelo da comunidade\n",
        "# print('Carregando o modelo ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "# # BitsAndBytes é um framework com funções customizadas para\n",
        "# # otimização com precisão 8-bit, multiplicações de matrizes e funções de quantização\n",
        "# quantization_config = BitsAndBytesConfig(\n",
        "#    load_in_4bit=True, # Habilita a quantização de 4 bits para comprimir o modelo\n",
        "#    bnb_4bit_quant_type=\"nf4\", # Define o tipo de dados de quantização nas camadas (`fp4` e `nf4`).\n",
        "#    bnb_4bit_use_double_quant=True, # Quantização aninhada, onde as constantes de quantização da primeira quantização são quantizadas novamente.\n",
        "#    bnb_4bit_compute_dtype=torch.bfloat16 # # Os gradientes dos pesos são computados em 16-bit. Define o tipo computacional que pode ser diferente do tempo de entrada. Por exemplo, as entradas podem ser fp32, mas a computação pode ser definida como bf16 para acelerações.\n",
        "# )\n",
        "\n",
        "# # Se GPU Disponível\n",
        "# if GPU_ENABLE:\n",
        "#   # Carrega o modelo com a otimização BitsAndBytesConfig\n",
        "#   print (\"Carregando o LLM com GPU\")\n",
        "#   model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "#                                              #torch_dtype=torch.float16, #default\n",
        "#                                              trust_remote_code=True, # Carrega de um repositório confiável\n",
        "#                                              quantization_config=quantization_config,\n",
        "#                                              device_map=\"auto\"\n",
        "#                                              )\n",
        "# else:\n",
        "#   # Carrega o modelo sem a otimização BitsAndBytesConfig\n",
        "#   print (\"Carregando o LLM sem GPU\")\n",
        "#   model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "#                                              #torch_dtype=torch.float16, #default\n",
        "#                                              trust_remote_code=True, # Carrega de um repositório confiável\n",
        "#                                              device_map=\"auto\"\n",
        "#                                              )\n",
        "\n",
        "# # Coloca o modelo e modo avaliação\n",
        "# model.eval()\n",
        "\n",
        "# # Aumentar a velocidade\n",
        "# # https://huggingface.co/docs/transformers/main/perf_torch_compile\n",
        "# model = torch.compile(model)\n",
        "\n",
        "# print(\"Tempo de carregamento do modelo LLM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doIqirI05Dos"
      },
      "source": [
        "### 2.4.2 - Carregamento LLama 3.1 com 8 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "82b0b27542d840caaf07d6da26f82564",
            "69bebc3000474c39b6ba93fa32bcbe4e",
            "395c6470cf354acda9fc5dcdda05333f",
            "64ddc2f01ea840e1bc29d9c1d734b984",
            "e3183a4aa1b64cb89feb5e4b92c159d5",
            "ccff3c34d3b84370bdfa6c275ff93c88",
            "b86f76334b3642369564ad3f3fefad59",
            "f33f64223da14062a645e29c0ff00c95",
            "8abee8205c874cb0aab4db5f98463699",
            "6149c16948b14710b51a1992a44ace35",
            "6f26bf496ffd41fba6b9df73c715e77f",
            "ff2876b1ad6147e1b46afe0f5bf7f64a",
            "d147a8e4c06c4fc9bf627eb82d33618c",
            "2e3b828ab0c14c2abfbad03eb682333f",
            "ed894764fb8e408bbc49b4a7c30f4d51",
            "f4dfa53cbc3141208d71c7bdb46b15eb",
            "72bad7767ddd43d08f32ad92598f0801",
            "30003cc10e5f4a3bbdfae9aa4c336acc",
            "d2a3b47628724bff97183936180cfe1a",
            "674ce8e7227c4e05972e13ceb484c887",
            "e192116f58a94c15888562d87572035b",
            "995c7b6122d14add98d661b844917d74",
            "f1f83b0ab9634a718be6d7cd5fbd48e4",
            "84717008302d4dcbaaeb317a06e2244d",
            "d65ae82d524a4643add4c444ce8c16fd",
            "64e4e4d993674404a94842a5e2bc9e3f",
            "7e9cdd345909478aa06b5ea135b83bd5",
            "0f4aac58c094400b980a55a21ced3aa2",
            "6801c723b9314871ac7f44fd7b5aa5a3",
            "f3c2c34db76a4bc9b74cdce5553d6294",
            "5c55818b0bee4b948f8493110db26306",
            "ad6d608122a741a785f9dca4a8274ecc",
            "196493a56a7b4cd68acb4412e39c42a0",
            "7b8533cbd4a54da1b7e9a7764bb5f37a",
            "fa0e89f52c09418cbe31d38d8f1571aa",
            "07563a93f475415193ee74077ed3681e",
            "4f85da339afb458086f9136d4ac4d5e0",
            "c774f24af06e4f3e98767e589fca2889",
            "512372c439604cb5a1fb652c42ab2313",
            "dca004b35c974d27b52399aec64d11d0",
            "96c5343993f940c5b6883e3ca9443df4",
            "e5991acdb2a84e29b1f7a6f18418a440",
            "adf081d786de4e4782e7aec0ea9acdd0",
            "3b58ea038cb548c1b87969a958421ae9",
            "19cfc095f2f04f689c6229046bf7edb0",
            "57b4ffb228b544739198a06936be68bf",
            "024d98fa11e94e2196e7cc27ff71c1f8",
            "fbf31927d73a46d7825d3cfebba1b4cc",
            "3f66c5339e594b4596965aebc2e1293a",
            "334df13bc642462fab2eb7c4b43608ff",
            "dad3edd97f6a4e58a8fab33da8484cbb",
            "f6d12cc4a02a4b7bb2cb9726618e0ce7",
            "455aa9a23e8d45ffa4db195f9ddb0f82",
            "c4e49bc773414ab6aee05651673d2064",
            "2a850d1e7a414bd59a330e8e8e3e8ae9",
            "4467a831fc104eeaa028217b2bd6c727",
            "7a0fda5cfeef4e18b00576b6661f34ed",
            "88b570e477b0461aa895ae042ec2acc8",
            "f9640b65324343e29154feda04019d47",
            "94df08720aab44d9b629fefd920f7e4e",
            "7254a7575c9c4d57a234d1956c5f97da",
            "5a45097561d74c86b5fd060482fabcf3",
            "ca00d2e80ebe44329647ecc375bd8070",
            "29f519d173ac4918beb0d632bde45bc1",
            "a43af1b3edea4d0f9e23603d5a0dceab",
            "83078e0f247043c2a8bac1a0cc1e0626",
            "55c83dd09cba48409a27593ba2b78ccd",
            "1b3efe21f42e44819d3e92642d97d1fb",
            "7a148858398c40cbbf8d0f6f68216acd",
            "978fc7cd005e4d618e4bd5a74957ebaa",
            "667c8d288310494f8ae4922559b10c3e",
            "926ec72916824af2a6282d86c1fc8ebc",
            "15f3161caa1643979e7cc8b53484bd0e",
            "7ef02d998f3e4d9ca8415f981534d76e",
            "eabb4c45f4e04191808c050eed7683fb",
            "f7d82f4826b5440cb5ef392e117044ed",
            "c88d67f605c34dcea971051166dea79b",
            "704669fb0a3b4f90afca6c2185d170e9",
            "0f84f0f9bcb74f0fb2adeb20d06cd435",
            "2675275f28a8445cae4a3797e71e375e",
            "8dd37d685bbd4f169e2fc78e536e40ab",
            "7b180a5104de477a8a5138e22e8b6653",
            "081c65f497ab48bf807c80382ae50b2b",
            "e07a045b3a5442af895e069b7ffedd18",
            "f63fd26662cd40c9b98234a732475dbe",
            "3f7ed62f097148aab7c541d54b37dbbc",
            "b6f894a0d9e94d3180e4e496f088c3e2",
            "57b3b2f61bc94d28bab74f1b4642fc6b",
            "6b8d0704901e46cf8c8009b0e98ae75e",
            "d50c6fd648014aa6aade6954f4b7ce9b",
            "2b5dc1a8b9d34199b82a1509fc8b9de1",
            "24de5aa82b714d12939bf2fa97aa5bed",
            "8d1c4e23b65f48eb8268952e34de3f61",
            "5a3cbf9af6b541ec8e6f77c0b7d75194",
            "6571e0aec12a41e186366e3771caa1fc",
            "c044aca116104afea4d949122e180042",
            "1bb009b2309e4691b963da8515c3aab8",
            "e02d69ee8d624addb5652fee1bab7182",
            "390e9906f3bb4db58ec001f13e90a5cf"
          ]
        },
        "id": "WTFnuVQ3R0gp",
        "outputId": "65ec17fe-21a4-4805-8ed5-474ae9283105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregando o modelo meta-llama/Meta-Llama-3.1-8B-Instruct da comunidade...\n",
            "Carregando o LLM com GPU\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82b0b27542d840caaf07d6da26f82564",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff2876b1ad6147e1b46afe0f5bf7f64a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1f83b0ab9634a718be6d7cd5fbd48e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b8533cbd4a54da1b7e9a7764bb5f37a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19cfc095f2f04f689c6229046bf7edb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4467a831fc104eeaa028217b2bd6c727",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c83dd09cba48409a27593ba2b78ccd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "704669fb0a3b4f90afca6c2185d170e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b8d0704901e46cf8c8009b0e98ae75e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tempo de carregamento do modelo LLM:  0:02:55 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "# Carregando o Modelo da comunidade\n",
        "print('Carregando o modelo ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "# BitsAndBytes é um framework com funções customizadas para\n",
        "# otimização com precisão 8-bit, multiplicações de matrizes e funções de quantização\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "   load_in_8bit=True, # Habilita a quantização de 8 bits\n",
        ")\n",
        "\n",
        "# Se GPU Disponível\n",
        "if GPU_ENABLE:\n",
        "  # Carrega o modelo com a otimização BitsAndBytesConfig\n",
        "  print (\"Carregando o LLM com GPU\")\n",
        "  model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "                                             #torch_dtype=torch.float16, #default\n",
        "                                             trust_remote_code=True, # Carrega de um repositório confiável\n",
        "                                             quantization_config=quantization_config,\n",
        "                                             device_map=\"auto\"\n",
        "                                             )\n",
        "\n",
        "else:\n",
        "  # Carrega o modelo sem a otimização BitsAndBytesConfig\n",
        "  print (\"Carregando o LLM sem GPU\")\n",
        "  model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "                                             #torch_dtype=torch.float16, #default\n",
        "                                             trust_remote_code=True, # Carrega de um repositório confiável\n",
        "                                             device_map=\"auto\"\n",
        "                                             )\n",
        "\n",
        "# Coloca o modelo e modo avaliação\n",
        "model.eval()\n",
        "\n",
        "# Aumentar a velocidade\n",
        "# https://huggingface.co/docs/transformers/main/perf_torch_compile\n",
        "model = torch.compile(model)\n",
        "\n",
        "print(\"Tempo de carregamento do modelo LLM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXO6VWCkDG_5"
      },
      "source": [
        "### 2.4.3 - Carregamento LLama 3.1 com 16 bits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBs_EGq7DJaQ"
      },
      "outputs": [],
      "source": [
        "# # Importando as bibliotecas do Modelo\n",
        "# from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
        "# import torch\n",
        "# import time\n",
        "\n",
        "# # Guarda o tempo de início do carregamento do modelo\n",
        "# tempo_inicio = time.time()\n",
        "\n",
        "# # Carregando o Modelo da comunidade\n",
        "# print('Carregando o modelo ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "# # Se GPU Disponível\n",
        "# if GPU_ENABLE:\n",
        "#   # Carrega o modelo com a otimização BitsAndBytesConfig\n",
        "#   print (\"Carregando o LLM com GPU\")\n",
        "#   model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "#                                              #torch_dtype=torch.float16, #default\n",
        "#                                              trust_remote_code=True, # Carrega de um repositório confiável#\n",
        "#                                              device_map=\"auto\"\n",
        "#                                              )\n",
        "\n",
        "# else:\n",
        "#   # Carrega o modelo sem a otimização BitsAndBytesConfig\n",
        "#   print (\"Carregando o LLM sem GPU\")\n",
        "#   model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "#                                              #torch_dtype=torch.float16, #default\n",
        "#                                              trust_remote_code=True, # Carrega de um repositório confiável\n",
        "#                                              device_map=\"cpu\"\n",
        "#                                              )\n",
        "\n",
        "# # Coloca o modelo e modo avaliação\n",
        "# model.eval()\n",
        "\n",
        "# # Aumentar a velocidade\n",
        "# # https://huggingface.co/docs/transformers/main/perf_torch_compile\n",
        "# model = torch.compile(model)\n",
        "\n",
        "# print(\"Tempo de carregamento do modelo LLM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E11NM4T6pmpP",
        "outputId": "7ea42374-6f9f-46ab-8942-9f2d702a46c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OptimizedModule(\n",
            "  (_orig_mod): LlamaForCausalLM(\n",
            "    (model): LlamaModel(\n",
            "      (embed_tokens): Embedding(128256, 4096)\n",
            "      (layers): ModuleList(\n",
            "        (0-31): 32 x LlamaDecoderLayer(\n",
            "          (self_attn): LlamaSdpaAttention(\n",
            "            (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "            (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
            "            (v_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n",
            "            (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "            (rotary_emb): LlamaRotaryEmbedding()\n",
            "          )\n",
            "          (mlp): LlamaMLP(\n",
            "            (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
            "            (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n",
            "            (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n",
            "            (act_fn): SiLU()\n",
            "          )\n",
            "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
            "      (rotary_emb): LlamaRotaryEmbedding()\n",
            "    )\n",
            "    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXgoG2ZvuHFI",
        "outputId": "6a253f94-c860-429c-ac30-8e709826bbe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": [\n",
            "    128001,\n",
            "    128008,\n",
            "    128009\n",
            "  ],\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": false,\n",
            "    \"_load_in_8bit\": true,\n",
            "    \"bnb_4bit_compute_dtype\": \"float32\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"fp4\",\n",
            "    \"bnb_4bit_use_double_quant\": false,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": false,\n",
            "    \"load_in_8bit\": true,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": {\n",
            "    \"factor\": 8.0,\n",
            "    \"high_freq_factor\": 4.0,\n",
            "    \"low_freq_factor\": 1.0,\n",
            "    \"original_max_position_embeddings\": 8192,\n",
            "    \"rope_type\": \"llama3\"\n",
            "  },\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysqp5fuyRWc4",
        "outputId": "7cbbabfe-d1cc-444b-a7cb-975e9d0ea526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131072\n"
          ]
        }
      ],
      "source": [
        "print(model.config.max_position_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpGMYgt6zWtX"
      },
      "source": [
        "Tamanho do vocabulário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT7nQq3Q0ALQ",
        "outputId": "4902e369-aafc-4bba-b7e6-184937cd2be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128256\n"
          ]
        }
      ],
      "source": [
        "print(model.config.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLdmeB6kLUUf"
      },
      "source": [
        "## 2.5 - Configuração da geração de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1eEVDtDLaNF",
        "outputId": "40920b90-0334-4c60-cbaa-99b62afa3016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GenerationConfig antes:\n",
            " GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    128001,\n",
            "    128008,\n",
            "    128009\n",
            "  ],\n",
            "  \"temperature\": 0.6,\n",
            "  \"top_p\": 0.9\n",
            "}\n",
            "\n",
            "GenerationConfig depois:\n",
            " GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    128001,\n",
            "    128008,\n",
            "    128009\n",
            "  ],\n",
            "  \"max_new_tokens\": 512,\n",
            "  \"temperature\": 0.1,\n",
            "  \"top_p\": 0.9\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "# Instância as configurações do modelo\n",
        "generation_config = GenerationConfig.from_pretrained(nome_modelo)\n",
        "\n",
        "print(\"GenerationConfig antes:\\n\",generation_config)\n",
        "generation_config.max_new_tokens = 512 # Preenche até um comprimento máximo especificado com o argumento max_length ou até o comprimento de entrada máximo aceitável para o modelo se esse argumento não for fornecido.\n",
        "#generation_config.max_length = 4096 # (Default 4096)\n",
        "# Se do_sample é true setar temperature e top_p, caso contrário se do_sample é false remover temperature e top_p.\n",
        "generation_config.do_sample = True # (Default True) Se definido como True, este parâmetro permite estratégias de decodificação como amostragem multinomial, amostragem multinomial de busca de feixe, amostragem Top-K e amostragem Top-p. Todas essas estratégias selecionam o próximo token da distribuição de probabilidade em todo o vocabulário com vários ajustes específicos da estratégia.\n",
        "generation_config.temperature = 0.1 # (Default 0.6) A temperatura é um parâmetro que controla a aleatoriedade da saída do LLM. Uma temperatura mais alta resultará em um texto mais criativo e imaginativo, enquanto uma temperatura mais baixa resultará em um texto mais preciso e factual.\n",
        "#generation_config.top_k = 3  # Top-k diz ao modelo para escolher o próximo token entre os 'k' tokens principais de sua lista, classificados por probabilidade.\n",
        "#generation_config.top_p = 0.9 # (Default 0.9) Top-p é mais dinâmico que top-k e é frequentemente usado para excluir resultados com probabilidades mais baixas. Portanto, se você definir p como 0,75, excluirá os 25% inferiores dos resultados prováveis.\n",
        "#generation_config.repetition_penalty = 1.20 # Penaliza a repetição e visa evitar frases que se repetem sem nada de realmente interessante.\n",
        "#generation_config.num_return_sequences=1, # Retorna uma única sentença da saída.\n",
        "#generation_config.pad_token_id=generation_config.eos_token_id\n",
        "print(\"GenerationConfig depois:\\n\",generation_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGiVSTl1rwAe"
      },
      "source": [
        "## 2.6 - Cria o pipeline usando Langchain\n",
        "\n",
        "Cria o pipeline com a classe [HuggingFacePipeline](https://api.python.langchain.com/en/latest/llms/langchain.llms.huggingface_pipeline.HuggingFacePipeline.html) do langchain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7kqNDonwh49"
      },
      "source": [
        "Passagem direta do pipeline Huggingface.\n",
        "\n",
        "Configura o pipeline do Huggingface usando o modelo e tokenizador previamente carregado e passa para o HuggingFacePipeline do langchain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2WhTkmAZrNj",
        "outputId": "081a325c-35ee-4472-ca0c-7b38d03ef6e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model 'OptimizedModule' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "#from langchain.llms import HuggingFacePipeline\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "# Configura o pipeline do HuggingFace\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id = tokenizer.eos_token_id,\n",
        "    # return_full_text=True,  # (Default True) Langchain espera o texto completo\n",
        "    generation_config=generation_config, # Passa as configurações da geração de texto para o pipeline\n",
        ")\n",
        "\n",
        "# Carrega o pipeline do Langchain\n",
        "# https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n",
        "model_llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFReKYmi8bdb",
        "outputId": "b5779390-6b00-42b4-e8ce-d6f3e060fbf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mHuggingFacePipeline\u001b[0m\n",
            "Params: {'model_id': 'gpt2', 'model_kwargs': None, 'pipeline_kwargs': None}\n"
          ]
        }
      ],
      "source": [
        "print(model_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qezcBkxnEdR"
      },
      "source": [
        "# 3 - Analisando a geração de textos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Pd6-h0YD8U"
      },
      "source": [
        "## 3.1 - Geração de texto simples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QP-2tC8YOFW",
        "outputId": "00d77888-0fef-43d7-d7af-c500744b0cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 <|begin_of_text|>\n",
            "1 Como\n",
            "2 Ġemp\n",
            "3 il\n",
            "4 har\n",
            "5 Ġelementos\n",
            "6 Ġem\n",
            "7 Ġuma\n",
            "8 Ġpil\n",
            "9 ha\n",
            "10 ?\n"
          ]
        }
      ],
      "source": [
        "# Define o documento base\n",
        "documento = \"Como empilhar elementos em uma pilha?\"\n",
        "#documento = \"How to push elements in a stack\"\n",
        "#documento = \"O comando SQL para extrair todos os usuários cujo nome começa com A é:\"\n",
        "#documento = \"Bom dia professor, tudo bem ?\"\n",
        "# documento = \"The SQL command to extract all the users whose name starts with A is:\"\n",
        "#documento = \"How to push elements in a stack\"\n",
        "#documento = \"Write code for finding the prime number in python ?\"\n",
        "# documento = \"Escrever código para encontrar o número primo em python?\"\n",
        "\n",
        "# Prepara o prompt para enviar ao modelo realizando sua tokenização\n",
        "# Se pt for especificado, ele retornará tensores em vez de lista de inteiros python e tokenizará os documentos\n",
        "input = tokenizer(documento, return_tensors=\"pt\")\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in input.input_ids[0]:\n",
        "    # print(tup.item())\n",
        "    print(\"{} {}\".format(i, tokenizer.convert_ids_to_tokens(tup.item())))\n",
        "    i= i + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K8bt1GYnPET"
      },
      "source": [
        "Submete o texto ao llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y19uoUNF7qq3"
      },
      "outputs": [],
      "source": [
        "# Executa o prompt no llm\n",
        "resultado = model_llm.invoke(documento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-SeyGqq0GO8"
      },
      "source": [
        "Mostra o resultado em linhas menores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mPCXA6ay5v_",
        "outputId": "04283a36-dbf1-4c3b-b09e-acccad2029b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Como empilhar elementos em uma pilha? Como empilhar elementos em uma pilha?\n",
            "Aqui estão algumas dicas para empilhar eleme\n",
            "ntos em uma pilha:\n",
            "1. Escolha um local plano e estável para a pilha.\n",
            "2. Certifique-se de que os elementos sejam estáveis\n",
            " e não sejam muito pesados para serem empilhados.\n",
            "3. Comece com o elemento mais pesado ou mais grande na base da pilha.\n",
            "\n",
            "4. Coloque os elementos subsequentes em cima do elemento anterior, certificando-se de que eles estejam firmes e não seja\n",
            "m inclinados.\n",
            "5. Continue adicionando elementos à pilha, certificando-se de que cada elemento esteja firme e não esteja \n",
            "inclinado.\n",
            "6. Certifique-se de que a pilha esteja equilibrada e não esteja inclinada para um lado.\n",
            "7. Se necessário, use\n",
            " apoios ou suportes para manter a pilha estável.\n",
            "8. Certifique-se de que a pilha esteja longe de áreas de tráfego ou áre\n",
            "as onde possa ser perturbada.\n",
            "9. Se a pilha for muito alta, considere usar uma estrutura de apoio, como uma prateleira o\n",
            "u uma estante.\n",
            "10. Certifique-se de que a pilha esteja segura e não esteja em perigo de cair.\n",
            "\n",
            "Além disso, aqui estão al\n",
            "gumas dicas adicionais para empilhar elementos em uma pilha:\n",
            "\n",
            "* Use elementos de tamanho similar para evitar que a pilha\n",
            " seja instável.\n",
            "* Evite empilhar elementos que sejam muito diferentes em tamanho ou peso.\n",
            "* Certifique-se de que a pilha\n",
            " esteja longe de fontes de calor ou fontes de luz intensa.\n",
            "* Evite empilhar elementos que sejam muito frágeis ou quebrad\n",
            "iços.\n",
            "* Certifique-se de que a pilha esteja longe de áreas de alta umidade ou áreas de alta pressão.\n",
            "\n",
            "Lembre-se de que a\n",
            " segurança é a prioridade ao empilhar elementos em uma pilha. Se você tiver alguma dúvida ou preocupação, considere cons\n",
            "ultar um profissional para ajudar a criar uma pilha segura e estável. Como empilhar elementos em uma pilha?\n",
            "Aqui estão a\n",
            "lgumas dicas para empilhar elementos em uma pilha:\n",
            "1. Escolha um local plano e estável para a pilha.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostra os resultados\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL0Eb3NczJyS"
      },
      "source": [
        "## 3.2 - Geração de texto com Prompt\n",
        "\n",
        "https://medium.com/@princekrampah/langchain-building-language-model-applications-c54cfe7219cb\n",
        "\n",
        "Repositório de pompts: https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy4cXYy1zNnT"
      },
      "outputs": [],
      "source": [
        "# Define o documento base\n",
        "documento = \"Como empilhar elementos em uma pilha?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E4vL6ipzU-r"
      },
      "source": [
        "Cria o templade de prompt usando a classe [PromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html#langchain.prompts.prompt.PromptTemplate) para submeter ao langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRgntVK6zRY0",
        "outputId": "3fb2f75e-f10d-4245-f180-1d4384beac60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['texto'] input_types={} partial_variables={} template='Pergunta: {texto}\\nResposta: Responda passo a passo.\\n'\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"Pergunta: {texto}\n",
        "Resposta: Responda passo a passo.\n",
        "\"\"\"\n",
        "\n",
        "# Cria o prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"texto\"],\n",
        "    template = prompt_template)\n",
        "\n",
        "# Motra o prompt\n",
        "print(prompt)\n",
        "\n",
        "# Mostra o prompt final\n",
        "#prompt_final = prompt.format(text=texto)\n",
        "#print(prompt_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqyeMAf_zU-0"
      },
      "source": [
        "Submete o prompt ao llm usando o langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp4ey3WizU-0",
        "outputId": "e2820535-5022-4a69-9cf0-f434c8ea90fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>>Mostra o resultado total\n",
            "Pergunta: Como empilhar elementos em uma pilha?\n",
            "Resposta: Responda passo a passo.\n",
            "1. Certifique-se de que o elemento inferior da pilha esteja firme e estável.\n",
            "2. Coloque o elemento seguinte na pilha, garantindo que esteja alinhado com o elemento inferior.\n",
            "3. Continue adicionando elementos à pilha, alinhando cada elemento com o elemento abaixo dele.\n",
            "4. Certifique-se de que a pilha esteja equilibrada e estável antes de adicioná-la a qualquer superfície.\n",
            "5. Se necessário, use suportes ou bases para manter a pilha estável e evitar que ela caia.\n",
            "\n",
            "Pergunta: Como manter a pilha estável?\n",
            "Resposta: Responda passo a passo.\n",
            "1. Certifique-se de que cada elemento da pilha esteja firme e estável.\n",
            "2. Verifique se a pilha está equilibrada e não está inclinada para um lado.\n",
            "3. Se necessário, use suportes ou bases para manter a pilha estável.\n",
            "4. Certifique-se de que a pilha esteja em uma superfície plana e estável.\n",
            "5. Evite colocar a pilha em uma superfície inclinada ou instável.\n",
            "\n",
            "Pergunta: O que fazer se a pilha cair?\n",
            "Resposta: Responda passo a passo.\n",
            "1. Mantenha a calma e não tente pegar os elementos que caíram.\n",
            "2. Verifique se a pilha está danificada ou se os elementos estão intactos.\n",
            "3. Se os elementos estiverem danificados, descarte-os e substitua-os por novos.\n",
            "4. Se os elementos estiverem intactos, coloque-os de volta na pilha, certificando-se de que estejam alinhados e estáveis.\n",
            "5. Verifique se a pilha está estável e equilibrada antes de adicioná-la a qualquer superfície. \n",
            "\n",
            "Pergunta: O que fazer se a pilha for muito alta?\n",
            "Resposta: Responda passo a passo.\n",
            "1. Verifique se a pilha está estável e equilibrada.\n",
            "2. Se a pilha for muito alta, considere dividir a pilha em duas ou mais pilhas menores.\n",
            "3. Certifique-se de que cada pilha menor esteja estável e equilibrada.\n",
            "4. Coloque as pilhas menores em uma superfície plan\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Instancia o chain\n",
        "chain = prompt | model_llm\n",
        "\n",
        "# Executa o prompt no llm\n",
        "#resultado = chain.invoke(input={\"texto\": documento})\n",
        "resultado = chain.invoke({\"texto\": documento})\n",
        "\n",
        "# Mostra o resultado total\n",
        "print(\">>>Mostra o resultado total\")\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DYsPrT40Jm_"
      },
      "source": [
        "Mostra o resultado em linhas menores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO9eXepAzU-0",
        "outputId": "185749f1-9593-4cf2-919b-a58cb54cbf17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pergunta: Como empilhar elementos em uma pilha?\n",
            "Resposta: Responda passo a passo.\n",
            "1. Certifique-se de que o elemento inf\n",
            "erior da pilha esteja firme e estável.\n",
            "2. Coloque o elemento seguinte na pilha, garantindo que esteja alinhado com o ele\n",
            "mento inferior.\n",
            "3. Continue adicionando elementos à pilha, alinhando cada elemento com o elemento abaixo dele.\n",
            "4. Certif\n",
            "ique-se de que a pilha esteja equilibrada e estável antes de adicioná-la a qualquer superfície.\n",
            "5. Se necessário, use su\n",
            "portes ou bases para manter a pilha estável e evitar que ela caia.\n",
            "\n",
            "Pergunta: Como manter a pilha estável?\n",
            "Resposta: Res\n",
            "ponda passo a passo.\n",
            "1. Certifique-se de que cada elemento da pilha esteja firme e estável.\n",
            "2. Verifique se a pilha está\n",
            " equilibrada e não está inclinada para um lado.\n",
            "3. Se necessário, use suportes ou bases para manter a pilha estável.\n",
            "4. \n",
            "Certifique-se de que a pilha esteja em uma superfície plana e estável.\n",
            "5. Evite colocar a pilha em uma superfície inclin\n",
            "ada ou instável.\n",
            "\n",
            "Pergunta: O que fazer se a pilha cair?\n",
            "Resposta: Responda passo a passo.\n",
            "1. Mantenha a calma e não ten\n",
            "te pegar os elementos que caíram.\n",
            "2. Verifique se a pilha está danificada ou se os elementos estão intactos.\n",
            "3. Se os el\n",
            "ementos estiverem danificados, descarte-os e substitua-os por novos.\n",
            "4. Se os elementos estiverem intactos, coloque-os d\n",
            "e volta na pilha, certificando-se de que estejam alinhados e estáveis.\n",
            "5. Verifique se a pilha está estável e equilibrad\n",
            "a antes de adicioná-la a qualquer superfície. \n",
            "\n",
            "Pergunta: O que fazer se a pilha for muito alta?\n",
            "Resposta: Responda pass\n",
            "o a passo.\n",
            "1. Verifique se a pilha está estável e equilibrada.\n",
            "2. Se a pilha for muito alta, considere dividir a pilha e\n",
            "m duas ou mais pilhas menores.\n",
            "3. Certifique-se de que cada pilha menor esteja estável e equilibrada.\n",
            "4. Coloque as pilh\n",
            "as menores em uma superfície plan\n"
          ]
        }
      ],
      "source": [
        "print_linhas_menores(resultado,120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wraIGw4Qce7d"
      },
      "source": [
        "Submete o prompt ao llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a31M3GZDce7e",
        "outputId": "d3b34bbf-e054-445b-89c6-610259f85cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>>Mostra o resultado total\n",
            "Pergunta: Como empilhar elementos em uma pilha?\n",
            "Resposta: Responda passo a passo.\n",
            "1. Certifique-se de que a base da pilha esteja firme e estável.\n",
            "2. Coloque o primeiro elemento na base da pilha.\n",
            "3. Coloque o segundo elemento em cima do primeiro, garantindo que esteja alinhado e firme.\n",
            "4. Continue adicionando elementos, um por vez, em cima dos outros, garantindo que cada elemento esteja alinhado e firme.\n",
            "5. Certifique-se de que a pilha esteja equilibrada e não esteja inclinada para um lado.\n",
            "6. Se necessário, ajuste a pilha para garantir que ela esteja firme e estável.\n",
            "\n",
            "Observação: Se você estiver empilhando objetos pesados ou grandes, é recomendável ter alguém para ajudar a segurar a pilha enquanto você adiciona os elementos. Além disso, certifique-se de que a superfície em que você está empilhando os objetos esteja plana e estável. \n",
            "\n",
            "Dicas adicionais:\n",
            "- Certifique-se de que cada elemento esteja firme e não esteja inclinado para um lado.\n",
            "- Não coloque objetos muito pesados ou grandes em cima de outros, pois isso pode causar a pilha a cair.\n",
            "- Se você estiver empilhando objetos frágeis, certifique-se de que eles estejam protegidos com papel ou outro material para evitar danos.\n",
            "- Se você estiver empilhando objetos que precisam ser organizados por tamanho ou tipo, certifique-se de que eles estejam alinhados corretamente. \n",
            "\n",
            "Espero que essas dicas tenham ajudado! Se você tiver mais alguma pergunta, sinta-se à vontade para perguntar. \n",
            "\n",
            "Se você quiser aprender mais sobre como empilhar elementos em uma pilha, aqui estão algumas dicas adicionais:\n",
            "- Certifique-se de que a base da pilha esteja firme e estável.\n",
            "- Coloque os elementos mais pesados ou grandes na base da pilha.\n",
            "- Coloque os elementos mais leves ou menores em cima dos outros.\n",
            "- Certifique-se de que cada elemento esteja firme e não esteja inclinado para um lado.\n",
            "- Não coloque objetos muito pesados ou grandes em cima de outros, pois isso pode causar a pilha a cair.\n",
            "- Se você estiver empilh\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "import langchain\n",
        "\n",
        "# Instancia o chain\n",
        "chain = prompt | model_llm\n",
        "\n",
        "# Executa o prompt no llm\n",
        "resultado = chain.invoke({\"texto\": documento})\n",
        "\n",
        "print(\">>>Mostra o resultado total\")\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fkf18je3hCw"
      },
      "source": [
        "# 4 - Exemplos de tipos de prompts com langchain\n",
        "\n",
        "* **zero-shot (0-shot) prompts - Solicitação direta**\n",
        "\n",
        "    Usado quando você deseja que o modelo gere uma resposta sem exemplos. Esses prompts podem ser úteis para questões gerais ou tarefas em que fornecer exemplos é desnecessário ou pode causar confusão.\n",
        "\n",
        "    Use prompts de disparo 0 quando confiar no conhecimento geral do modelo para fornecer uma resposta suficiente.\n",
        "\n",
        "\n",
        "* **one-shot (1-shot) prompts - Solicitação com um exemplo**\n",
        "\n",
        "    Forneça um único exemplo do resultado desejado, ajudando a orientar a resposta do modelo. Essa abordagem pode ser útil quando você precisar de um formato ou estilo específico ou quando a tarefa exigir algum nível de orientação.\n",
        "\n",
        "    Use prompts únicos quando quiser empurrar o modelo na direção certa sem sobrecarregá-lo com vários exemplos.\n",
        "\n",
        "* **few-shot (N-shot) prompts - Solicitação com vários  exemplos**\n",
        "\n",
        "    Ofereça vários exemplos, permitindo que o modelo aprenda com várias instâncias. Essas instruções podem ser benéficas ao lidar com tarefas complexas, onde fornecer uma série de exemplos ajuda o modelo a compreender melhor o resultado desejado.\n",
        "\n",
        "    Use prompts multi-shot quando um único exemplo pode não ser suficiente para orientar o modelo ou quando você deseja demonstrar um padrão ou tendência.\n",
        "\n",
        "\n",
        "Referências:\n",
        "https://anilktalla.medium.com/prompt-engineering-1-shot-prompting-283a0b2b1467\n",
        "\n",
        "https://www.ssw.com.au/rules/shot-prompts/\n",
        "\n",
        "https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n",
        "\n",
        "Repositório de pompts: https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFCVV0-zRV-z"
      },
      "source": [
        "## 4.1 - Zero-shot - Solicitação direta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Q8s7VMRWii"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPromptZeroShot(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"{texto}\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKv2NSZ_RyRy",
        "outputId": "9774d172-28c9-4ac6-89e6-7d43afbaf987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Me fale sobre algoritmos. Algoritmos são sequências de passos que são usados para resolver problemas ou realizar tarefas\n",
            ". Eles são usados em uma ampla gama de áreas, incluindo ciência de dados, inteligência artificial, processamento de ling\n",
            "uagem natural e muito mais. Algoritmos podem ser implementados em diferentes linguagens de programação e podem ser usado\n",
            "s para realizar tarefas como classificação, regressão, clustering e muito mais.\n",
            "\n",
            "Aqui estão alguns exemplos de algoritmo\n",
            "s:\n",
            "\n",
            "1. Algoritmo de ordenação: é usado para organizar dados em ordem crescente ou decrescente.\n",
            "2. Algoritmo de busca: é \n",
            "usado para encontrar um valor específico em uma lista de dados.\n",
            "3. Algoritmo de classificação: é usado para classificar \n",
            "dados em categorias.\n",
            "4. Algoritmo de regressão: é usado para prever valores futuros com base em dados históricos.\n",
            "5. Alg\n",
            "oritmo de clustering: é usado para agrupar dados semelhantes.\n",
            "\n",
            "Algoritmos podem ser classificados em diferentes tipos, i\n",
            "ncluindo:\n",
            "\n",
            "1. Algoritmos determinísticos: são algoritmos que sempre produzem o mesmo resultado para um conjunto de entra\n",
            "das.\n",
            "2. Algoritmos aleatórios: são algoritmos que produzem resultados diferentes para o mesmo conjunto de entradas.\n",
            "3. A\n",
            "lgoritmos de aprendizado de máquina: são algoritmos que podem aprender a partir de dados e melhorar seu desempenho com o\n",
            " tempo.\n",
            "\n",
            "Algoritmos são fundamentais para a resolução de problemas complexos e são usados em uma ampla gama de áreas, in\n",
            "cluindo:\n",
            "\n",
            "1. Ciência de dados: algoritmos são usados para analisar e visualizar dados.\n",
            "2. Inteligência artificial: algor\n",
            "itmos são usados para criar sistemas que podem aprender e se adaptar.\n",
            "3. Processamento de linguagem natural: algoritmos \n",
            "são usados para analisar e entender linguagem humana.\n",
            "4. Criptografia: algoritmos são usados para proteger dados e garan\n",
            "tir a segurança de comunicações.\n",
            "\n",
            "Em resumo, algoritmos são sequências de passos que são usados para resolver problemas \n",
            "ou realizar tarefas. Eles são fundamentais para a resolução de problemas complexos e são usados em uma ampla gama de áre\n",
            "as. Algoritmos podem ser classificados em diferentes tipos e são\n"
          ]
        }
      ],
      "source": [
        "texto = 'Me fale sobre algoritmos.'\n",
        "\n",
        "resultado = avaliarPromptZeroShot(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IarUzHxsRaGp"
      },
      "source": [
        "## 4.2 - One-shot - Solicitação com um exemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSR2ZDJ9R1zI"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPromptOneShot(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
        "\\'Elementos são adicionados e removidos apenas no topo da pilha.\\' -> \\'11\\'\n",
        "Agora conte a quantidade de tokens da sentença: \\'{texto}\\'\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-TbZqa3R1zJ",
        "outputId": "7b489d3b-8b99-4605-bb6a-f65597e94bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
            "'Elementos são adicionados e removidos apenas no topo da pilha.' -> '11'\n",
            "Agora conte a quantidade de tokens da sentença: 'Operação de adição em uma pilha é chamada de push.' -> '9'\n",
            "\n",
            "Aqui está a solução em Python:\n",
            "```python\n",
            "def count_tokens(sentence):\n",
            "    return len(sentence.split())\n",
            "\n",
            "# Teste a função\n",
            "sentence = 'Operação de adição em uma pilha é chamada de push.'\n",
            "print(count_tokens(sentence))  # Saída: 9\n",
            "``` \n",
            "Aqui está a explicação da solução:\n",
            "- A função `count_tokens` recebe uma sentença como parâmetro.\n",
            "- A função utiliza a função `split()` para dividir a sentença em uma lista de tokens.\n",
            "- A função `len()` é utilizada para contar a quantidade de tokens na lista.\n",
            "- O resultado é retornado pela função. \n",
            "\n",
            "Espero que isso ajude! Se tiver alguma dúvida, sinta-se à vontade para perguntar. \n",
            "\n",
            "**Observação:** A função `split()` é utilizada para dividir a sentença em tokens. Por padrão, ela utiliza o caractere de espaço em branco como separador. Se você quiser utilizar um separador diferente, basta passar o caractere como parâmetro da função `split()`. Por exemplo: `sentence.split(',')` para dividir a sentença em tokens utilizando a vírgula como separador. \n",
            "\n",
            "**Observação 2:** A função `count_tokens` não remove os tokens vazios da lista. Se você quiser remover os tokens vazios, basta adicionar a linha `tokens = [token for token in tokens if token!= '']` antes de contar a quantidade de tokens. Por exemplo: \n",
            "```python\n",
            "def count_tokens(sentence):\n",
            "    tokens = sentence.split()\n",
            "    tokens = [token for token in tokens if token!= '']\n",
            "    return len(tokens)\n",
            "``` \n",
            "Espero que isso ajude! Se tiver alguma dúvida, sinta-se à vontade para perguntar. \n",
            "\n",
            "**Observação 3:** A função `count_tokens` não remove os tokens que são apenas caracteres de pontuação. Se você quiser remover os tokens que são apenas caracteres de pontuação, basta adicionar a linha `tokens = [token for token in tokens if not token.isalpha() and not token.isdigit()]` antes de contar a quantidade de tokens. Por exemplo: \n",
            "```python\n",
            "def count_tokens(sentence):\n",
            "    tokens = sentence.split()\n",
            "    tokens = [token for token in tokens if not token.isalpha() and not token.isdigit()]\n",
            "    return len(tokens)\n",
            "``` \n",
            "Espero\n"
          ]
        }
      ],
      "source": [
        "texto = 'Operação de adição em uma pilha é chamada de push.'\n",
        "\n",
        "resultado = avaliarPromptOneShot(texto)\n",
        "\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CfTAE56Rahg"
      },
      "source": [
        "## 4.3 - Few-shot - Solicitação com vários exemplos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9tYmFU1R_iN"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPromptFewShot(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
        "\\'Pilha e fila são estruturas de dados.\\' -> \\'7\\'\\n\n",
        "\\'Elementos são adicionados e removidos apenas do topo da pilha.\\' -> \\'10\\'\n",
        "\\'Pilhas são fundamentais na computação.\\' -> \\'5\\'\n",
        "Agora conte a quantidade de tokens da sentença: \\'{texto}\\'\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RPeN1tHR_iO",
        "outputId": "210a0e6d-bee3-40ba-ec1c-e5d4fb3339dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
            "'Pilha e fila são estruturas de dados.' -> '7'\n",
            "\n",
            "'Elementos são adicionados e removidos apenas do topo da pilha.' -> '10'\n",
            "'Pilhas são fundamentais na computação.' -> '5'\n",
            "Agora conte a quantidade de tokens da sentença: 'Operação de adição em uma pilha é chamada de push.' -> '7'  # noqa: E501\n",
            "'Operação de remoção em uma pilha é chamada de pop.' -> '7'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos.' -> '6'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação.' -> '7'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca.' -> '9'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura.' -> '10'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em profundidade.' -> '11'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura e profundidade.' -> '13'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura e profundidade em grafos.' -> '15'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura e profundidade em grafos e árvores.' -> '17'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura e profundidade em grafos e árvores binárias.' -> '19'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura e profundidade em grafos e árvores binárias ordenadas.' -> '21'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura e profundidade em grafos e árvores binárias ordenadas e pesadas.' -> '23'  # noqa: E501\n",
            "'Pilhas são usadas em muitos algoritmos de ordenação e busca em largura e profundidade em grafos e árvores binárias ordenadas e pesadas com ciclos.' -> '25'  # noqa: E501\n",
            "'P\n"
          ]
        }
      ],
      "source": [
        "texto = 'Operação de adição em uma pilha é chamada de push.'\n",
        "\n",
        "resultado = avaliarPromptFewShot(texto)\n",
        "\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPqNyPAXV2aH"
      },
      "source": [
        "## 4.4 - Tarefa Emparelhadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T02c792rOUw"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarTextoTarefa(texto, entrada=None):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  if entrada:\n",
        "    prompt_template = \"\"\"Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma resposta que conclua adequadamente a solicitação.\n",
        "\n",
        "### Instruções:\n",
        "{texto}\n",
        "\n",
        "### Entrada:\n",
        "{entrada}\n",
        "\n",
        "### Resposta:\"\"\"\n",
        "  else:\n",
        "    prompt_template = \"\"\"Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua adequadamente a solicitação.\n",
        "\n",
        "### Instruções:\n",
        "{texto}\n",
        "\n",
        "### Resposta:\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  if entrada:\n",
        "    prompt = PromptTemplate(\n",
        "      input_variables=[\"texto\",\"entrada\"],\n",
        "      template = prompt_template)\n",
        "  else:\n",
        "    prompt = PromptTemplate(\n",
        "      input_variables=[\"texto\"],\n",
        "      template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  if entrada:\n",
        "    # Executa o prompt no llm\n",
        "    resultado = chain.invoke({\"texto\": texto, \"entrada\": entrada})\n",
        "\n",
        "  else:\n",
        "    resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsuoM33I35aU",
        "outputId": "61c0a170-150f-42b8-e370-3bc412197961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### In\n",
            "struções:\n",
            "Me fale sobre algoritmos.\n",
            "\n",
            "### Resposta: \n",
            "Algoritmos são sequências de passos lógicos que permitem resolver pr\n",
            "oblemas ou realizar tarefas de forma eficiente. Eles são fundamentais em diversas áreas, como ciência da computação, mat\n",
            "emática, economia e engenharia, entre outras. Algoritmos podem ser representados de forma escrita, utilizando linguagens\n",
            " de programação, ou de forma visual, utilizando diagramas de fluxo.\n",
            "\n",
            "Um algoritmo típico consiste em uma sequência de et\n",
            "apas que podem incluir:\n",
            "\n",
            "1.  **Entrada**: Receber dados ou informações necessárias para realizar a tarefa.\n",
            "2.  **Process\n",
            "amento**: Realizar cálculos, comparações ou outras operações com os dados.\n",
            "3.  **Saída**: Produzir resultados ou saídas \n",
            "baseados nos dados processados.\n",
            "\n",
            "Algoritmos podem ser classificados em diferentes tipos, como:\n",
            "\n",
            "*   **Algoritmos de orde\n",
            "nação**: Organizam conjuntos de dados em ordem crescente ou decrescente.\n",
            "*   **Algoritmos de busca**: Localizam elemento\n",
            "s específicos em conjuntos de dados.\n",
            "*   **Algoritmos de resolução de problemas**: Encontram soluções para problemas com\n",
            "plexos.\n",
            "\n",
            "Algoritmos são essenciais em diversas áreas, como:\n",
            "\n",
            "*   **Ciência da computação**: Algoritmos são usados para d\n",
            "esenvolver software, sistemas operacionais e redes.\n",
            "*   **Matemática**: Algoritmos são usados para resolver problemas ma\n",
            "temáticos, como equações e sistemas de equações.\n",
            "*   **Economia**: Algoritmos são usados para analisar dados econômicos \n",
            "e prever tendências.\n",
            "\n",
            "Em resumo, algoritmos são sequências de passos lógicos que permitem resolver problemas ou realizar\n",
            " tarefas de forma eficiente. Eles são fundamentais em diversas áreas e podem ser representados de forma escrita ou visua\n",
            "l. Algoritmos são usados para resolver problemas complexos e são essenciais em diversas áreas, como ciência da computaçã\n",
            "o, matemática e economia.  Algoritmos são usados em diversas áreas, como ciência da computação, matemática, economia e e\n",
            "ngenharia, entre outras. Eles são fundamentais para resolver problemas complexos e são usados em diversas áreas, como ci\n",
            "ência da computação, matemática, economia e engenharia,\n"
          ]
        }
      ],
      "source": [
        "texto = 'Me fale sobre algoritmos.'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GtAPgns4Qxu",
        "outputId": "8d5b862b-125c-4aca-9d7e-839f9bf48609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma re\n",
            "sposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### Instruções:\n",
            "Dada a fórmula química, calcule a massa molar.\n",
            "\n",
            "### Ent\n",
            "rada:\n",
            "CaCl2\n",
            "\n",
            "### Resposta: \n",
            "A massa molar de CaCl2 pode ser calculada usando a fórmula: massa molar = (massa atômica do \n",
            "Ca) + (2 * massa atômica do Cl). A massa atômica do Ca é de aproximadamente 40 g/mol e a massa atômica do Cl é de aproxi\n",
            "madamente 35,5 g/mol. Portanto, a massa molar de CaCl2 é: massa molar = 40 + (2 * 35,5) = 40 + 71 = 111 g/mol. A massa m\n",
            "olar de CaCl2 é de 111 g/mol.  A resposta final é 111.  ### Instruções:\n",
            "Dada a fórmula química, calcule a massa molar.\n",
            "\n",
            "\n",
            "### Entrada:\n",
            "CaCl2\n",
            "\n",
            "### Resposta: \n",
            "A massa molar de CaCl2 pode ser calculada usando a fórmula: massa molar = (massa atôm\n",
            "ica do Ca) + (2 * massa atômica do Cl). A massa atômica do Ca é de aproximadamente 40 g/mol e a massa atômica do Cl é de\n",
            " aproximadamente 35,5 g/mol. Portanto, a massa molar de CaCl2 é: massa molar = 40 + (2 * 35,5) = 40 + 71 = 111 g/mol. A \n",
            "massa molar de CaCl2 é de 111 g/mol.  A resposta final é 111.  ### Instruções:\n",
            "Dada a fórmula química, calcule a massa m\n",
            "olar.\n",
            "\n",
            "### Entrada:\n",
            "CaCl2\n",
            "\n",
            "### Resposta: \n",
            "A massa molar de CaCl2 pode ser calculada usando a fórmula: massa molar = (mas\n",
            "sa atômica do Ca) + (2 * massa atômica do Cl). A massa atômica do Ca é de aproximadamente 40 g/mol e a massa atômica do \n",
            "Cl é de aproximadamente 35,5 g/mol. Portanto, a massa molar de CaCl2 é: massa molar = 40 + (2 * 35,5) = 40 + 71 = 111 g/\n",
            "mol. A massa molar de CaCl2 é de 111 g/mol.  A resposta final é 111.  ### Instruções:\n",
            "Dada a fórmula química,\n"
          ]
        }
      ],
      "source": [
        "texto = 'Dada a fórmula química, calcule a massa molar.'\n",
        "\n",
        "entrada = 'CaCl2'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto, entrada)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPcD-rCP4cUy",
        "outputId": "e6011a2a-1881-4438-d479-97a86b5307c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma re\n",
            "sposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### Instruções:\n",
            "Faça quatro perguntas sobre a seguinte passagem:\n",
            "\n",
            "### E\n",
            "ntrada:\n",
            "A anatomia de uma abelha é bastante intrincada. Tem três partes do corpo: a cabeça, o tórax e o abdômen. A cabeç\n",
            "a consiste em órgãos sensoriais, três olhos simples e dois olhos compostos e vários apêndices. O tórax tem três pares de\n",
            " pernas e dois pares de asas, enquanto o abdômen contém a maioria dos órgãos da abelha, incluindo o sistema reprodutivo \n",
            "e o sistema digestivo.\n",
            "\n",
            "### Resposta: \n",
            "1. Quais são as três partes do corpo de uma abelha?\n",
            "2. Quais são os órgãos sensor\n",
            "iais da cabeça de uma abelha?\n",
            "3. Quais são os órgãos que o abdômen de uma abelha contém?\n",
            "4. Quais são os órgãos que o tó\n",
            "rax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de\n",
            " uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma a\n",
            "belha contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha \n",
            "contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha contém\n",
            "? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Q\n",
            "uais são os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais s\n",
            "ão os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais são os \n",
            "órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma abelha contém? 4. Quais são os órgãos\n",
            " que o tórax de uma abelha contém? 4. Quais são os órgãos que o tórax de uma ab\n"
          ]
        }
      ],
      "source": [
        "texto = 'Faça quatro perguntas sobre a seguinte passagem:'\n",
        "\n",
        "entrada = 'A anatomia de uma abelha é bastante intrincada. Tem três partes do corpo: a cabeça, o tórax e o abdômen. A cabeça consiste em órgãos sensoriais, três olhos simples e dois olhos compostos e vários apêndices. O tórax tem três pares de pernas e dois pares de asas, enquanto o abdômen contém a maioria dos órgãos da abelha, incluindo o sistema reprodutivo e o sistema digestivo.'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto, entrada)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3eWu-AF4lxZ",
        "outputId": "dcd88b48-4b06-4b3e-d1cf-f8639d5f6329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma re\n",
            "sposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### Instruções:\n",
            "Analise o documento jurídico fornecido e explique os po\n",
            "ntos-chave.\n",
            "\n",
            "### Entrada:\n",
            "O seguinte é um trecho de um contrato entre duas partes, rotulado como \"Empresa A\" e \"Empresa \n",
            "B\": \"A Empresa A concorda em fornecer assistência razoável à Empresa B para garantir a precisão das demonstrações financ\n",
            "eiras que fornece. Isso inclui permitir à Empresa um acesso razoável ao pessoal e outros documentos que possam ser neces\n",
            "sários para a revisão da Empresa B. A Empresa B concorda em manter o documento fornecido pela Empresa A em confiança e n\n",
            "ão divulgará as informações a terceiros sem a permissão explícita da Empresa A\".\n",
            "\n",
            "### Resposta: \n",
            "Os pontos-chave desse c\n",
            "ontrato incluem:\n",
            "\n",
            "1.  **Obrigação de Assistência da Empresa A**: A Empresa A se compromete a fornecer assistência razoáv\n",
            "el à Empresa B para garantir a precisão das demonstrações financeiras. Isso significa que a Empresa A deve ser acessível\n",
            " e transparente em relação às informações financeiras que fornece à Empresa B.\n",
            "2.  **Acesso à Informação**: A Empresa A \n",
            "concede à Empresa B um acesso razoável ao pessoal e a outros documentos necessários para a revisão das demonstrações fin\n",
            "anceiras. Isso garante que a Empresa B tenha todas as informações necessárias para realizar sua revisão de forma eficaz.\n",
            "\n",
            "3.  **Confidencialidade**: A Empresa B se compromete a manter o documento fornecido pela Empresa A em confiança. Isso s\n",
            "ignifica que a Empresa B não pode compartilhar as informações contidas no documento com terceiros sem a permissão explíc\n",
            "ita da Empresa A.\n",
            "4.  **Divulgação de Informações**: A Empresa B não pode divulgar as informações a terceiros sem a perm\n",
            "issão explícita da Empresa A. Isso garante que as informações financeiras sejam protegidas e não sejam compartilhadas se\n",
            "m a autorização da Empresa A.\n",
            "\n",
            "Em resumo, o contrato estabelece uma parceria entre as duas empresas, onde a Empresa A fo\n",
            "rnece assistência e acesso às informações financeiras, e a Empresa B se compromete a manter a confidencialidade e não di\n",
            "vulgar as informações sem a permissão da Empresa A. Isso garante a precisão das demonstrações financeiras e protege as i\n",
            "nformações financeiras das duas empresas.  A resposta final.  Obrigado por ler.  Se você tiver mais alguma pergunta, não\n",
            " hesite em perguntar.  Boa sorte com sua pesquisa.  Atenciosamente, [Seu Nome].  Se você tiver mais alguma pergunta, não\n",
            " hesite em perguntar.  Boa sorte com sua pesquisa.  Atenciosamente, [Seu Nome].  Se você tiver mais alguma pergunta, não\n",
            " hesite em perguntar.  Boa sorte com sua pesquisa.  Atenciosamente, [Seu Nome].  Se você tiver mais alguma pergunta, não\n",
            " hesite em perg\n"
          ]
        }
      ],
      "source": [
        "texto = 'Analise o documento jurídico fornecido e explique os pontos-chave.'\n",
        "\n",
        "entrada = 'O seguinte é um trecho de um contrato entre duas partes, rotulado como \"Empresa A\" e \"Empresa B\": \"A Empresa A concorda em fornecer assistência razoável à Empresa B para garantir a precisão das demonstrações financeiras que fornece. Isso inclui permitir à Empresa um acesso razoável ao pessoal e outros documentos que possam ser necessários para a revisão da Empresa B. A Empresa B concorda em manter o documento fornecido pela Empresa A em confiança e não divulgará as informações a terceiros sem a permissão explícita da Empresa A\".'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto, entrada)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgiKWHXxafKf"
      },
      "source": [
        "# 5 - Exemplos de injeção de padrões em prompts\n",
        "\n",
        " A injeção de padrões faz ignora filtros ou manipula o LLM usando prompts cuidadosamente elaborados que fazem o modelo ignorar instruções anteriores ou executar ações não intencionais.\n",
        "\n",
        " https://medium.com/@austin-stubbs/llm-security-types-of-prompt-injection-d7ad8d7d75a3\n",
        "\n",
        "Repositório de pompts: https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epsEHDsGQJAC"
      },
      "source": [
        "### 5.1 - Extração de Informação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToMVt5GkkqEw"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarEI(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"TEXTO: {texto}\n",
        "Dado o texto acima, extraia informações importantes no formato abaixo:\n",
        "<CHAVE>:<VALOR>\n",
        "\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCeR9lv5_Fxd",
        "outputId": "f8d1a671-2812-44e5-f3c0-36e52a4e4ae5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXTO: Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\n",
            "Dado o texto acima, extraia informações importantes no formato abaixo:\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "<CHAVE>:<VALOR>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "texto = \"Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)\"\\\n",
        "        \"foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico \"\\\n",
        "        \"britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação \"\\\n",
        "        \"teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina \"\\\n",
        "        \"de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente \"\\\n",
        "        \"considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas \"\\\n",
        "        \"realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser \"\\\n",
        "        \"homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\"\n",
        "\n",
        "resultado = avaliarEI(texto)\n",
        "\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KX7dU3GlyRr"
      },
      "source": [
        "## 5.2 - Entidade nomeada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-RNaXagl0ur"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarEN(texto):\n",
        "\n",
        "  prompt_template = \"\"\"Detecte as entidades nomeadas no texto a seguir delimitado por aspas triplas.\n",
        "Retorne apenas a resposta no formato json com spans(Um array que representa o intervalo de caracteres (índices) nos quais a entidade nomeada ocorre no texto original. O primeiro valor no array é o índice inicial(\\\"inicio\\\") e o segundo é o índice final(\\\"fim\\\")) das entidades nomeadas com os campos \\\"entidadeNomeada\\\", \\\"tipo\\\", \\\"span\\\".\n",
        "Retorne todas as entidades.\n",
        "'''{texto}'''\n",
        "\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kkprHhiNmLFi",
        "outputId": "7600b975-904e-4e1b-c331-9c8e3b829fa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detecte as entidades nomeadas no texto a seguir delimitado por aspas triplas.\n",
            "Retorne apenas a resposta no formato json \n",
            "com spans(Um array que representa o intervalo de caracteres (índices) nos quais a entidade nomeada ocorre no texto origi\n",
            "nal. O primeiro valor no array é o índice inicial(\"inicio\") e o segundo é o índice final(\"fim\")) das entidades nomeadas \n",
            "com os campos \"entidadeNomeada\", \"tipo\", \"span\".\n",
            "Retorne todas as entidades.\n",
            "'''Alan Mathison Turing (Londres, 23 de jun\n",
            "ho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)foi um matemático, cientista da computação, lógico, criptoanalista, \n",
            "filósofo e biólogo teórico britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação\n",
            " teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina de Turing, que pode ser \n",
            "considerada um modelo de um computador de uso geral. Ele é amplamente considerado o pai da ciência da computação teórica\n",
            " e da inteligência artificial. Apesar dessas realizações ele nunca foi totalmente reconhecido em seu país de origem dura\n",
            "nte sua vida por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.'''\n",
            "{\n",
            " \n",
            " \"entidades\": [\n",
            "    {\n",
            "      \"entidadeNomeada\": \"Alan Mathison Turing\",\n",
            "      \"tipo\": \"Pessoa\",\n",
            "      \"span\": [\n",
            "        0\n",
            ",\n",
            "        19\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"Londres\",\n",
            "      \"tipo\": \"Local\",\n",
            "      \"span\": [\n",
            "        20,\n",
            "\n",
            "        26\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"23 de junho de 1912\",\n",
            "      \"tipo\": \"Data\",\n",
            "      \"span\": [\n",
            " \n",
            "       27,\n",
            "        41\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"Wilmslow\",\n",
            "      \"tipo\": \"Local\",\n",
            "      \"span\": [\n",
            " \n",
            "       42,\n",
            "        49\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"Cheshire\",\n",
            "      \"tipo\": \"Local\",\n",
            "      \"span\": [\n",
            " \n",
            "       50,\n",
            "        57\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"7 de junho de 1954\",\n",
            "      \"tipo\": \"Data\",\n",
            "      \"s\n",
            "pan\": [\n",
            "        58,\n",
            "        72\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"matemático\",\n",
            "      \"tipo\": \"Profissão\",\n",
            "  \n",
            "    \"span\": [\n",
            "        73,\n",
            "        81\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"cientista da computação\",\n",
            "      \"tip\n",
            "o\": \"Profissão\",\n",
            "      \"span\": [\n",
            "        82,\n",
            "        96\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"lógico\",\n",
            "      \"t\n",
            "ipo\": \"Profissão\",\n",
            "      \"span\": [\n",
            "        97,\n",
            "        103\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"criptoanalista\n",
            "\",\n",
            "      \"tipo\": \"Profissão\",\n",
            "      \"span\": [\n",
            "        104,\n",
            "        113\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\": \"fi\n",
            "lósofo\",\n",
            "      \"tipo\": \"Profissão\",\n",
            "      \"span\": [\n",
            "        114,\n",
            "        121\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"entidadeNomeada\n",
            "\": \"biólogo teórico\",\n",
            "      \"tipo\": \"Profissão\",\n",
            "      \"span\": [\n",
            "        122,\n",
            "        134\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"en\n",
            "tidadeNomeada\": \"Turing\",\n",
            "      \"tipo\": \"P\n"
          ]
        }
      ],
      "source": [
        "texto = \"Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)\"\\\n",
        "        \"foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico \"\\\n",
        "        \"britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação \"\\\n",
        "        \"teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina \"\\\n",
        "        \"de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente \"\\\n",
        "        \"considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas \"\\\n",
        "        \"realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser \"\\\n",
        "        \"homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\"\n",
        "\n",
        "resultado = avaliarEN(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3rpc-_yfN3p"
      },
      "source": [
        "## 5.3 - Análise de sentimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRYDcKB3UwBm"
      },
      "source": [
        "### 5.3.1 - Análise de sentimentos 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C4ZW8PZQnxAW"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarAS1(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Classifique os exemplos a seguir de acordo com as seguintes polaridades Positivo, Negativo e Neutro.\n",
        "EXEMPLO:\\n {texto}\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lQ4S-1saUwBn",
        "outputId": "2452a0b7-3beb-44b4-ee5a-34e31dafa44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifique os exemplos a seguir de acordo com as seguintes polaridades Positivo, Negativo e Neutro.\n",
            "EXEMPLO:\n",
            " 1 - Minha Experiência na loja foi incrível.2 - Eu acho que podiam melhorar o produto.3 - O atendimento foi horrível!4 - Não volto mais.5 - Recomendo demais a banoffe. É uma delícia!6 - O preço é um pouco alto.7 - Eu não gosto de banoffe.8 - O atendimento foi muito bom.9 - O produto é muito bom.10 - Eu não vou mais na loja.\n",
            "CLASSIFICAÇÃO:\n",
            "1 - Positivo2 - Negativo3 - Negativo4 - Negativo5 - Positivo6 - Neutro7 - Negativo8 - Positivo9 - Positivo10 - Negativo\n",
            "Observação: A classificação foi feita com base na polaridade do verbo principal da frase. Se o verbo principal for de ação positiva, a classificação será Positivo. Se o verbo principal for de ação negativa, a classificação será Negativo. Se o verbo principal for de ação neutra, a classificação será Neutro. Exemplo: “Eu acho que podiam melhorar o produto” (verbo principal é “acho”, que é neutro, portanto a classificação é Neutro). “O atendimento foi horrível!” (verbo principal é “foi”, que é negativo, portanto a classificação é Negativo). “O atendimento foi muito bom” (verbo principal é “foi”, que é positivo, portanto a classificação é Positivo). “Eu não vou mais na loja” (verbo principal é “vou”, que é negativo, portanto a classificação é Negativo). “O produto é muito bom” (verbo principal é “é”, que é positivo, portanto a classificação é Positivo). “Eu não gosto de banoffe” (verbo principal é “gosto”, que é negativo, portanto a classificação é Negativo). “Recomendo demais a banoffe” (verbo principal é “recomendo”, que é positivo, portanto a classificação é Positivo). “O preço é um pouco alto” (verbo principal é “é”, que é neutro, portanto a classificação é Neutro). “Minha Experiência na loja foi incrível” (verbo principal é “foi”, que é positivo, portanto a classificação é Positivo). “Eu acho que podiam melhorar o produto” (verbo principal é “acho”, que é neutro, portanto a classificação é Neutro).\n"
          ]
        }
      ],
      "source": [
        "texto = \"1 - Minha Experiência na loja foi incrível.\"\\\n",
        "        \"2 - Eu acho que podiam melhorar o produto.\"\\\n",
        "        \"3 - O atendimento foi horrível!\"\\\n",
        "        \"4 - Não volto mais.\"\\\n",
        "        \"5 - Recomendo demais a banoffe. É uma delícia!\"\n",
        "\n",
        "resultado = avaliarAS1(texto)\n",
        "\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNgeAi-MfJ-B"
      },
      "source": [
        "### 5.3.2 - Análise de sentimentos 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iXF9ShhDoAFI"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarAS2(texto):\n",
        "\n",
        "#   # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"DECLARAÇÕES: {texto}\n",
        "Classifique as declarações acima de acordo com as polaridades Positivo, Negativo e Neutro.\n",
        "Preserve a exata formatação do template apresentado: \\n\n",
        "###DECLARAÇÃO:<DECLARAÇÃO>\n",
        "###POLARIDADE:<POLARIDADE>.\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y2R_YBdrfJ-E",
        "outputId": "e3174a29-0599-445b-d879-5cb3a8295cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECLARAÇÕES: 1 - Minha Experiência na loja foi incrível.2 - Eu acho que podiam melhorar o produto.3 - O atendimento foi horrível!4 - Não volto mais.5 - Recomendo demais a banoffe. É uma delícia!\n",
            "Classifique as declarações acima de acordo com as polaridades Positivo, Negativo e Neutro.\n",
            "Preserve a exata formatação do template apresentado: \n",
            "\n",
            "###DECLARAÇÃO:<DECLARAÇÃO>\n",
            "###POLARIDADE:<POLARIDADE>. \n",
            "\n",
            "1 - Minha Experiência na loja foi incrível.\n",
            "###DECLARAÇÃO:Minha Experiência na loja foi incrível.\n",
            "###POLARIDADE:Positivo.\n",
            "\n",
            "2 - Eu acho que podiam melhorar o produto.\n",
            "###DECLARAÇÃO:Eu acho que podiam melhorar o produto.\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "3 - O atendimento foi horrível!\n",
            "###DECLARAÇÃO:O atendimento foi horrível!\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "4 - Não volto mais.\n",
            "###DECLARAÇÃO:Não volto mais.\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "5 - Recomendo demais a banoffe. É uma delícia!\n",
            "###DECLARAÇÃO:Recomendo demais a banoffe. É uma delícia!\n",
            "###POLARIDADE:Positivo. \n",
            "\n",
            "###DECLARAÇÃO:1 - Minha Experiência na loja foi incrível.\n",
            "###POLARIDADE:Positivo.\n",
            "\n",
            "###DECLARAÇÃO:2 - Eu acho que podiam melhorar o produto.\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###DECLARAÇÃO:3 - O atendimento foi horrível!\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###DECLARAÇÃO:4 - Não volto mais.\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###DECLARAÇÃO:5 - Recomendo demais a banoffe. É uma delícia!\n",
            "###POLARIDADE:Positivo. \n",
            "\n",
            "###DECLARAÇÃO:1 - Minha Experiência na loja foi incrível.\n",
            "###POLARIDADE:Positivo.\n",
            "\n",
            "###DECLARAÇÃO:2 - Eu acho que podiam melhorar o produto.\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###DECLARAÇÃO:3 - O atendimento foi horrível!\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###DECLARAÇÃO:4 - Não volto mais.\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###DECLARAÇÃO:5 - Recomendo demais a banoffe. É uma delícia!\n",
            "###POLARIDADE:Positivo. \n",
            "\n",
            "###DECLARAÇÃO:1 - Minha Experiência na loja foi incrível.\n",
            "###POLARIDADE:Positivo.\n",
            "\n",
            "###DECLARAÇÃO:2 - Eu acho que podiam melhorar o produto.\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###DECLARAÇÃO:3 - O atendimento foi horrível!\n",
            "###POLARIDADE:Negativo.\n",
            "\n",
            "###\n"
          ]
        }
      ],
      "source": [
        "texto = \"1 - Minha Experiência na loja foi incrível.\"\\\n",
        "        \"2 - Eu acho que podiam melhorar o produto.\"\\\n",
        "        \"3 - O atendimento foi horrível!\"\\\n",
        "        \"4 - Não volto mais.\"\\\n",
        "        \"5 - Recomendo demais a banoffe. É uma delícia!\"\n",
        "\n",
        "resultado = avaliarAS2(texto)\n",
        "\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdnnZIYcCYr9"
      },
      "source": [
        "## 5.4 - Pergunta e resposta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eDW7Mckg8Qj3"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPR(texto):\n",
        "  '''\n",
        "    Alterações no texto e tabulação impedem a geração da resposta.\n",
        "  '''\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Dado o texto a seguir: {texto}\\n\n",
        "          Gere quatro questões em língua portuguesa e suas respectivas respostas utilizando apenas o template abaixo.\\n\n",
        "          Preserve a exata formatação do template apresentado: \\n\n",
        "          PERGUNTA:<PERGUNTA>\n",
        "          RESPOSTA:<RESPOSTA>\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = prompt | model_llm\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke({\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qHGHQTUv72F3",
        "outputId": "648046cb-2f4e-4ef4-ca8f-a1648b097b2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dado o texto a seguir: Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\n",
            "\n",
            "          Gere quatro questões em língua portuguesa e suas respectivas respostas utilizando apenas o template abaixo.\n",
            "\n",
            "          Preserve a exata formatação do template apresentado: \n",
            "\n",
            "          PERGUNTA:<PERGUNTA>\n",
            "          RESPOSTA:<RESPOSTA> \n",
            "\n",
            "          Exemplo:\n",
            "          PERGUNTA: Qual é a data de nascimento de Alan Mathison Turing?\n",
            "          RESPOSTA: 23 de junho de 1912\n",
            "\n",
            "          PERGUNTA: Qual foi o ano de nascimento de Alan Mathison Turing?\n",
            "          RESPOSTA: 1912\n",
            "\n",
            "          PERGUNTA: Qual foi o ano de morte de Alan Mathison Turing?\n",
            "          RESPOSTA: 1954\n",
            "\n",
            "          PERGUNTA: Qual foi a data de morte de Alan Mathison Turing?\n",
            "          RESPOSTA: 7 de junho de 1954\n",
            "\n",
            "          PERGUNTA: Qual foi o ano em que Turing foi considerado o pai da ciência da computação teórica e da inteligência artificial?\n",
            "          RESPOSTA: Não há informação disponível sobre o ano em que Turing foi considerado o pai da ciência da computação teórica e da inteligência artificial.\n",
            "\n",
            "          PERGUNTA: Qual foi o ano em que Turing foi considerado o pai da ciência da computação teórica?\n",
            "          RESPOSTA: Não há informação disponível sobre o ano em que Turing foi considerado o pai da ciência da computação teórica.\n",
            "\n",
            "          PERGUNTA: Qual foi o ano em que Turing foi considerado o pai da inteligência artificial?\n",
            "          RESPOSTA: Não há informação disponível sobre o ano em que Turing foi considerado o pai da inteligência artificial.\n",
            "\n",
            "          PERGUNTA: Qual foi o ano em que Turing foi considerado o pai da ciência da computação?\n",
            "          RESPOSTA: Não há informação disponível sobre o ano em que Turing foi considerado o pai da ciência da computação.\n",
            "\n",
            "          PERGUNTA: Qual foi o ano em que Turing foi considerado o pai da ciência da computação teórica e da inteligência artificial?\n",
            "          RESPOSTA: Não há informação disponível sobre o ano em que Turing foi considerado o pai da ciência da computação teórica e da inteligência artificial.\n",
            "\n",
            "          PERGUNTA: Qual foi o ano em que Turing foi considerado o pai da ciência da computação teórica e da inteligência artificial?\n",
            "          RESPOSTA: Não há informação disponível sobre o ano em que Turing foi considerado o pai da ciência da computação teórica e da inteligência artificial.\n",
            "\n",
            "          PERGUNTA: Qual foi o\n"
          ]
        }
      ],
      "source": [
        "texto = \"Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)\"\\\n",
        "        \"foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico \"\\\n",
        "        \"britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação \"\\\n",
        "        \"teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina \"\\\n",
        "        \"de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente \"\\\n",
        "        \"considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas \"\\\n",
        "        \"realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser \"\\\n",
        "        \"homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\"\n",
        "\n",
        "resultado = avaliarPR(texto)\n",
        "\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfw5EjYDgDQm"
      },
      "source": [
        "# 6 - Exemplos de padrão de pessoa (padrão persona) em prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw9f51yZkf8o"
      },
      "source": [
        "## 6.1 Um matemático"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3cNZ6ykkqSYa"
      },
      "outputs": [],
      "source": [
        "def avaliarTexto(texto):\n",
        "\n",
        "  # Executa o texto no llm\n",
        "  resultado = model_llm.invoke(texto)\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jy63e1xykf8p",
        "outputId": "b2a65eb2-f766-4698-dfe3-6a3d93eb9302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva como se fosse um professor de matemática. Me explique no idioma português a importância do teorema de pitágoras.\n",
            " O teorema de Pitágoras é um dos conceitos mais importantes da matemática, pois ele relaciona a hipotenusa de um triângu\n",
            "lo retângulo com os catetos. O teorema de Pitágoras é uma ferramenta fundamental para resolver problemas de geometria e \n",
            "trigonometria, e é amplamente utilizado em diversas áreas, como engenharia, arquitetura, física e astronomia.\n",
            "\n",
            "O teorema\n",
            " de Pitágoras é frequentemente representado pela fórmula a² + b² = c², onde a e b são as medidas dos catetos e c é a med\n",
            "ida da hipotenusa. Essa fórmula é uma ferramenta poderosa para resolver problemas de triângulos retângulos, pois permite\n",
            " calcular a medida da hipotenusa a partir das medidas dos catetos.\n",
            "\n",
            "A importância do teorema de Pitágoras é que ele perm\n",
            "ite resolver problemas de geometria e trigonometria de forma eficiente e precisa. Além disso, o teorema de Pitágoras é u\n",
            "ma ferramenta fundamental para calcular distâncias e ângulos em triângulos retângulos, o que é essencial em diversas áre\n",
            "as, como engenharia, arquitetura e física.\n",
            "\n",
            "Além disso, o teorema de Pitágoras é uma ferramenta fundamental para resolve\n",
            "r problemas de trigonometria, pois permite calcular a medida de ângulos em triângulos retângulos. Isso é essencial em di\n",
            "versas áreas, como astronomia e navegação, onde a precisão dos cálculos é fundamental.\n",
            "\n",
            "Em resumo, o teorema de Pitágora\n",
            "s é uma ferramenta fundamental da matemática, pois permite resolver problemas de geometria e trigonometria de forma efic\n",
            "iente e precisa. Sua importância é amplamente reconhecida em diversas áreas, e é uma ferramenta essencial para qualquer \n",
            "pessoa que trabalhe com matemática.\n",
            "\n",
            "Aqui estão alguns exemplos de como o teorema de Pitágoras é utilizado em diversas á\n",
            "reas:\n",
            "\n",
            "* Engenharia: O teorema de Pitágoras é utilizado para calcular a distância entre dois pontos em um plano, o que é\n",
            " essencial em projetos de engenharia.\n",
            "* Arquitetura: O teorema de Pitágoras é utilizado para calcular a\n"
          ]
        }
      ],
      "source": [
        "texto = 'Escreva como se fosse um professor de matemática. Me explique no idioma português a importância do teorema de pitágoras.'\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTrJshC4gOiA"
      },
      "source": [
        "## 6.2 Um advogado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H6hEVjpCqymR"
      },
      "outputs": [],
      "source": [
        "def avaliarTexto(texto):\n",
        "\n",
        "  # Executa o texto no llm\n",
        "  resultado = model_llm.invoke(texto)\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bg_VZF7dg6o5",
        "outputId": "466a88bd-7ef8-4aef-9ccb-0311a96ed34c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva como se fosse um advogado brasileiro especialista em direito penal.         Pontue de forma resumida as possívei\n",
            "s penas para um caso de lesão corporal leve sem contexto de violência doméstica. \n",
            "\n",
            "Aqui estão as possíveis penas para um\n",
            " caso de lesão corporal leve sem contexto de violência doméstica:\n",
            "\n",
            "1.  **Multas**: A pena de multa é a mais comum para l\n",
            "esões corporais leves. O valor da multa pode variar de acordo com a gravidade da lesão e a situação do agressor. Em gera\n",
            "l, a multa pode variar de R$ 1.500 a R$ 10.000.\n",
            "2.  **Pena de prestação de serviços à comunidade**: Em alguns casos, o j\n",
            "uiz pode condenar o agressor a prestação de serviços à comunidade, como limpeza de ruas, trabalho em projetos sociais, e\n",
            "tc. A duração da prestação de serviços pode variar de acordo com a gravidade da lesão.\n",
            "3.  **Pena de reclusão**: Em caso\n",
            "s mais graves, o agressor pode ser condenado a uma pena de reclusão, que pode variar de 1 a 3 anos. No entanto, é import\n",
            "ante notar que a pena de reclusão é mais comum em casos de lesões corporais graves ou em casos de violência doméstica.\n",
            "4\n",
            ".  **Pena de suspensão do direito de dirigir**: Se o agressor for motorista, ele pode ser condenado a suspensão do direi\n",
            "to de dirigir por um período determinado.\n",
            "5.  **Pena de proibição de exercer atividade profissional**: Em alguns casos, \n",
            "o juiz pode condenar o agressor a proibição de exercer uma atividade profissional específica, como a prática de esportes\n",
            " ou a condução de veículos.\n",
            "\n",
            "É importante notar que as penas podem variar de acordo com a gravidade da lesão, a situação\n",
            " do agressor e a legislação específica do caso. Além disso, o juiz pode considerar a existência de circunstâncias atenua\n",
            "ntes ou agravantes ao determinar a pena. \n",
            "\n",
            "Em resumo, as possíveis penas para um caso de lesão corporal leve sem context\n",
            "o de violência doméstica incluem multas, pena de prestação de serviços à comunidade, pena de reclusão, pena de suspensão\n",
            " do direito de dirigir e pena de proibição de exerc\n"
          ]
        }
      ],
      "source": [
        "texto = \"Escreva como se fosse um advogado brasileiro especialista em direito penal. \\\n",
        "        Pontue de forma resumida as possíveis penas para um caso de lesão corporal leve sem contexto de violência doméstica.\"\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5Ij9_FZTqR"
      },
      "source": [
        "## 6.3 Um astrofísico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jhvOsGiVZTqZ"
      },
      "outputs": [],
      "source": [
        "def avaliarTexto(texto):\n",
        "\n",
        "  # Executa o texto no llm\n",
        "  resultado = model_llm.invoke(texto)\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fuvvmTx7AqSN",
        "outputId": "cbdcb6cd-eea3-4bd3-be7c-0649109c9d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva em português como se fosse um astrofísico. Me explique por que o universo está expandindo. O universo está em co\n",
            "nstante expansão devido à sua natureza fundamental, que é a expansão do espaço-tempo. Isso ocorre devido à energia de re\n",
            "pulsão que existe em todas as regiões do universo, conhecida como energia escura. A energia escura é uma forma de energi\n",
            "a que não interage com a matéria, mas que afeta a expansão do espaço-tempo. Ela é responsável pela aceleração da expansã\n",
            "o do universo, que foi observada em 1998 por uma equipe de cientistas liderada por Saul Perlmutter. A expansão do univer\n",
            "so é uma consequência direta da expansão do espaço-tempo, que é governada pelas leis da física de Einstein, conhecidas c\n",
            "omo a teoria da relatividade geral. A teoria da relatividade geral descreve como a gravidade é uma curvatura do espaço-t\n",
            "empo causada pela presença de massa e energia. A expansão do universo é uma consequência da curvatura do espaço-tempo, q\n",
            "ue é causada pela energia escura. A expansão do universo é uma das principais evidências da existência da energia escura\n",
            ", que é uma das principais questões abertas na cosmologia atual. A expansão do universo é uma consequência direta da exp\n",
            "ansão do espaço-tempo, que é governada pelas leis da física de Einstein, conhecidas como a teoria da relatividade geral.\n",
            " A teoria da relatividade geral descreve como a gravidade é uma curvatura do espaço-tempo causada pela presença de massa\n",
            " e energia. A expansão do universo é uma consequência da curvatura do espaço-tempo, que é causada pela energia escura. A\n",
            " expansão do universo é uma das principais evidências da existência da energia escura, que é uma das principais questões\n",
            " abertas na cosmologia atual. A expansão do universo é uma consequência direta da expansão do espaço-tempo, que é govern\n",
            "ada pelas leis da física de Einstein, conhecadas como a teoria da relatividade geral. A teoria da relatividade geral des\n",
            "creve como a gravidade é uma curvatura do espaço-tempo causada pela presença de massa e energia. A expansão do universo \n",
            "é uma consequência da curvatura do espaço-tempo, que é causada pela\n"
          ]
        }
      ],
      "source": [
        "texto = \"Escreva em português como se fosse um astrofísico. Me explique por que o universo está expandindo.\"\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aN8SgzyAfc_"
      },
      "source": [
        "Em algumas execuções o modelo responde em inglês."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GRoS9dFWZTqa",
        "outputId": "9a6264ce-733e-4ae8-8892-7dc394d1032e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Escreva como se fosse um astrofísico. Usando o idioma português, me explique por que o universo está expandindo. O unive\n",
            "rso está em expansão porque a matéria que o compõe está se afastando de outras partículas. Isso ocorre devido à energia \n",
            "de expansão, que é uma força que impulsiona a expansão do universo. A energia de expansão é uma propriedade fundamental \n",
            "do universo, e é responsável pela expansão do universo desde o Big Bang. A expansão do universo é uma consequência diret\n",
            "a da energia de expansão, e é observada em todas as escalas, desde a expansão das galáxias até a expansão do universo co\n",
            "mo um todo. A expansão do universo é uma das principais evidências da teoria do Big Bang, e é uma das principais razões \n",
            "pelas quais a teoria do Big Bang é considerada uma das teorias mais bem estabelecidas da física moderna.\n",
            "A expansão do u\n",
            "niverso é um fenômeno complexo que envolve a interação entre a matéria e a energia que o compõe. A matéria que o univers\n",
            "o é composto é composta por partículas que estão em constante movimento e interação, e a energia de expansão é a força q\n",
            "ue impulsiona a expansão do universo. A energia de expansão é uma propriedade fundamental do universo, e é responsável p\n",
            "ela expansão do universo desde o Big Bang. A expansão do universo é uma consequência direta da energia de expansão, e é \n",
            "observada em todas as escalas, desde a expansão das galáxias até a expansão do universo como um todo.\n",
            "\n",
            "A expansão do uni\n",
            "verso é um fenômeno que pode ser observado em diferentes escalas, desde a expansão das galáxias até a expansão do univer\n",
            "so como um todo. A expansão das galáxias é um fenômeno que pode ser observado em escalas menores, enquanto a expansão do\n",
            " universo como um todo é um fenômeno que pode ser observado em escalas maiores. A expansão das galáxias é um fenômeno qu\n",
            "e pode ser observado em diferentes tipos de galáxias, desde galáxias espirais até galáxias elípticas.\n",
            "\n",
            "A expansão do uni\n",
            "verso é um fenômeno que pode ser observado em diferentes tipos de objetos celestes, desde est\n"
          ]
        }
      ],
      "source": [
        "texto = 'Escreva como se fosse um astrofísico. Usando o idioma português, me explique por que o universo está expandindo.'\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWxaKJ1o3tWG"
      },
      "source": [
        "# 6 - Padrão de Verificação Cognitiva\n",
        "\n",
        "Divide perguntas complexas em subperguntas menores e gerenciáveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VNV4TEFZ3zBk",
        "outputId": "dfa4e2d3-6111-4249-a874-8f83a3ba25e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Em um caso de agressão corporal o indivíduo agredido sofreu sequelas permanentes e encontra-se impossibilitado de trabal\n",
            "har. O agressor poderá ser sentenciado à prisão e ao pagamento de indenização vitalícia? Considere a legislação brasilei\n",
            "ra. A resposta é sim.\n",
            "A Constituição Federal de 1988, em seu artigo 5º, inciso XLII, estabelece que a lei penal não excl\n",
            "uirá da sua aplicação os crimes contra a dignidade da pessoa humana, ressalvados os casos de extinção de punibilidade pr\n",
            "evistos em lei. Além disso, o Código Penal Brasileiro, em seu artigo 122, estabelece que a pena de prisão pode ser aplic\n",
            "ada em caso de crimes contra a vida, a liberdade, a integridade física e a saúde.\n",
            "Já o Código Civil Brasileiro, em seu a\n",
            "rtigo 186, estabelece que o agente que, de forma culposa, causar danos a outrem, ainda que não lhe seja imputável, será \n",
            "obrigado a reparar o dano. Além disso, o artigo 927 do mesmo Código Civil estabelece que o agente que, de forma culposa,\n",
            " causar danos a outrem, ainda que não lhe seja imputável, será obrigado a reparar o dano, e que a indenização pode ser f\n",
            "ixada em valor único, ou em parcelas mensais, até que o dano seja integralmente reparado.\n",
            "Portanto, considerando a legis\n",
            "lação brasileira, o agressor poderá ser sentenciado à prisão e ao pagamento de indenização vitalícia, caso o juiz consid\n",
            "ere que a agressão foi culposa e causou danos permanentes ao indivíduo agredido.\n",
            "Aqui estão os principais pontos da legi\n",
            "slação brasileira que se aplicam a esse caso:\n",
            "- Artigo 5º, inciso XLII, da Constituição Federal de 1988: A lei penal não\n",
            " excluirá da sua aplicação os crimes contra a dignidade da pessoa humana, ressalvados os casos de extinção de punibilida\n",
            "de previstos em lei.\n",
            "- Artigo 122 do Código Penal Brasileiro: A pena de prisão pode ser aplicada em caso de crimes contr\n",
            "a a vida, a liberdade, a integridade física e a saúde.\n",
            "- Artigo 186 do Código Civil Brasileiro: O agente que, de forma c\n",
            "ulposa, causar danos a outrem, ainda\n"
          ]
        }
      ],
      "source": [
        "texto = 'Em um caso de agressão corporal o indivíduo agredido sofreu sequelas '\\\n",
        "        'permanentes e encontra-se impossibilitado de trabalhar. O agressor poderá ser sentenciado ' \\\n",
        "        'à prisão e ao pagamento de indenização vitalícia? Considere a legislação brasileira.'\n",
        "\n",
        "resultado = model_llm.invoke(texto)\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M2DIo5e8uU_"
      },
      "source": [
        "# 7 - Pensamento em cadeia(Chain-of-Thought)\n",
        "\n",
        "Uma cadeia de prompts interconectados pode estimular o raciocínio nos modelos de linguagem.\n",
        "\n",
        "FONTE: https://arxiv.org/pdf/2201.11903.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCzzlI-FAxCX"
      },
      "source": [
        "Aumenta a quantidade de caracteres de saída do pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QxhzacFzAX7t",
        "outputId": "553c5fa6-82f8-4378-c4e8-2b951528249d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model 'OptimizedModule' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n",
            "<ipython-input-69-e9c1b13151d0>:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  model_llm = HuggingFacePipeline(\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "# Configura o pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id = tokenizer.eos_token_id,\n",
        "    trust_remote_code=True,\n",
        "    max_length=1024\n",
        ")\n",
        "\n",
        "# Carrega o pipeline\n",
        "# https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n",
        "model_llm = HuggingFacePipeline(\n",
        "    pipeline=pipe,\n",
        "    model_kwargs={\"temperature\": 0.1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nygjlPmZ_HL_"
      },
      "outputs": [],
      "source": [
        "texto = 'Q: Roger tem 5 bolas de tênis. Ele compra mais 2 pacotes de bolas de tênis.'\\\n",
        "        'Cada pacote tem 2 bolas de tênis. Quantas bolas de tênis Roger tem agora?'\\\n",
        "        'A: Roger tinha 5 bolas de tênis. 2 pacotes com 3 bolas de tênis em cada'\\\n",
        "        'um dá um total de 6 bolas de tênis. 5 + 6 = 11. A resposta é 11.'\\\n",
        "        '\\nQ: A cafeteria tinha 23 maçãs. Se eles usaram 20 delas para fazer uma'\\\n",
        "        'torta e depois compraram mais 6 maçãs, quantas maçãs tem na cafeteria?'\n",
        "\n",
        "resultado = model_llm.invoke(texto)\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttOpEPEZGzgy"
      },
      "outputs": [],
      "source": [
        "texto = 'Q: Roger tem 5 bolas de tênis. Ele compra mais 2 pacotes de bolas de tênis.'\\\n",
        "        'Cada pacote tem 2 bolas de tênis. Quantas bolas de tênis Roger tem agora?'\\\n",
        "        'A: Roger tinha 5 bolas de tênis. 2 pacotes com 3 bolas de tênis em cada'\\\n",
        "        'um dá um total de 6 bolas de tênis. 5 + 6 = 11. A resposta é 11.'\\\n",
        "        '\\nQ: A cafeteria tinha 23 maçãs. Se eles usaram 20 delas para fazer uma'\\\n",
        "        'torta e depois compraram mais 6 maçãs, quantas maçãs tem na cafeteria?'\n",
        "\n",
        "resultado = model_llm.invoke(texto, model_kwargs={\"temperature\": 0.1})\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2LRlh82_L9A"
      },
      "outputs": [],
      "source": [
        "texto = 'Q: Os números ímpares no grupo a seguir quando somados resultam em um' \\\n",
        "        'número par: 4, 8, 9, 15, 12, 2, 1.'\\\n",
        "        '\\nA: Somar todos os números ímpares (9, 15, 1) resulta em 25.'\\\n",
        "        '25 é um número ímpar. Portanto a assertiva anterior é Falsa.'\\\n",
        "        '\\nQ: Os números ímpares no grupo a seguir quando somados resultam'\\\n",
        "        'em um número par: 15, 32, 5, 13, 82, 7, 1.'\n",
        "\n",
        "resultado = model_llm.invoke(texto)\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGkSD1iS3E3N"
      },
      "source": [
        "# 8 - Refinamento de perguntas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkZohUZj3GxW"
      },
      "outputs": [],
      "source": [
        "# Importa das bibliotecas\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Apaga variável input existente\n",
        "try:\n",
        "    del input\n",
        "except NameError:\n",
        "    print(\"input não existe\")\n",
        "\n",
        "# Instancia o objeto de conversação\n",
        "conversation = ConversationChain(\n",
        "    llm=model_llm,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "texto = 'Sempre que eu fizer uma pergunta relacionada a computação, '\\\n",
        "        'sugira uma pergunta mais refinada considerando as especificidades de '\\\n",
        "        'estrutura de dados. Todo o texto deve ser escrito usando o idioma português brasileiro. '\\\n",
        "        'Pergunte se eu gostaria de utilizar a pergunta sugerida.'\n",
        "\n",
        "while True:\n",
        "  resposta = conversation.invoke(input=texto)\n",
        "  print(\"CHATGPT: \", resposta.get('response'))\n",
        "\n",
        "  texto = input(\"USER: \")\n",
        "  if texto.lower() == 'sair':\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "024d98fa11e94e2196e7cc27ff71c1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d12cc4a02a4b7bb2cb9726618e0ce7",
            "max": 4999802720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_455aa9a23e8d45ffa4db195f9ddb0f82",
            "value": 4999802720
          }
        },
        "07563a93f475415193ee74077ed3681e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c5343993f940c5b6883e3ca9443df4",
            "max": 4976698672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5991acdb2a84e29b1f7a6f18418a440",
            "value": 4976698672
          }
        },
        "081c65f497ab48bf807c80382ae50b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090811705a994611a7281cb7e23e5157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f4aac58c094400b980a55a21ced3aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f84f0f9bcb74f0fb2adeb20d06cd435": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_081c65f497ab48bf807c80382ae50b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_e07a045b3a5442af895e069b7ffedd18",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1521bc93d8434043ba07ab76ade23821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33269b9a764d417bac6f3287b906ed93",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67a49e8fb33b435d9b917b96d0474634",
            "value": 296
          }
        },
        "15f3161caa1643979e7cc8b53484bd0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17d556116b9a49bfb957497dde86a956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "196493a56a7b4cd68acb4412e39c42a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19cfc095f2f04f689c6229046bf7edb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57b4ffb228b544739198a06936be68bf",
              "IPY_MODEL_024d98fa11e94e2196e7cc27ff71c1f8",
              "IPY_MODEL_fbf31927d73a46d7825d3cfebba1b4cc"
            ],
            "layout": "IPY_MODEL_3f66c5339e594b4596965aebc2e1293a"
          }
        },
        "1b3efe21f42e44819d3e92642d97d1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926ec72916824af2a6282d86c1fc8ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_15f3161caa1643979e7cc8b53484bd0e",
            "value": "model-00004-of-00004.safetensors: 100%"
          }
        },
        "1bb009b2309e4691b963da8515c3aab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dd620f9a61b41fd9b2fe8018c47e961": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b272b8fbdd48de9e1744e729279e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68bfd77475c2445ba926220299931c4b",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f398683517c4f59b15748b3fff194cd",
            "value": 9085657
          }
        },
        "24de5aa82b714d12939bf2fa97aa5bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02d69ee8d624addb5652fee1bab7182",
            "placeholder": "​",
            "style": "IPY_MODEL_390e9906f3bb4db58ec001f13e90a5cf",
            "value": " 184/184 [00:00&lt;00:00, 9.73kB/s]"
          }
        },
        "2675275f28a8445cae4a3797e71e375e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f63fd26662cd40c9b98234a732475dbe",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f7ed62f097148aab7c541d54b37dbbc",
            "value": 4
          }
        },
        "29f519d173ac4918beb0d632bde45bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a850d1e7a414bd59a330e8e8e3e8ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a92f2020cb2450a9352089fa32dd673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dd620f9a61b41fd9b2fe8018c47e961",
            "placeholder": "​",
            "style": "IPY_MODEL_e5aa7bc32fcc4d5db6b6acf9b69019e4",
            "value": " 9.09M/9.09M [00:01&lt;00:00, 6.12MB/s]"
          }
        },
        "2b5dc1a8b9d34199b82a1509fc8b9de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c044aca116104afea4d949122e180042",
            "max": 184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bb009b2309e4691b963da8515c3aab8",
            "value": 184
          }
        },
        "2e3b828ab0c14c2abfbad03eb682333f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a3b47628724bff97183936180cfe1a",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_674ce8e7227c4e05972e13ceb484c887",
            "value": 23950
          }
        },
        "30003cc10e5f4a3bbdfae9aa4c336acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33269b9a764d417bac6f3287b906ed93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "334df13bc642462fab2eb7c4b43608ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362ceaaff6784e2daeb2052d857e60a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ecdfa95ef104502805b13840d05003e",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa6525ffad740e2a61717d8f33ffd3d",
            "value": "tokenizer.json: 100%"
          }
        },
        "390e9906f3bb4db58ec001f13e90a5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "395c6470cf354acda9fc5dcdda05333f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33f64223da14062a645e29c0ff00c95",
            "max": 855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8abee8205c874cb0aab4db5f98463699",
            "value": 855
          }
        },
        "3b58ea038cb548c1b87969a958421ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f66c5339e594b4596965aebc2e1293a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f7ed62f097148aab7c541d54b37dbbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40bc3d042386446cbf29f396af98c572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e5da2829654257969c12e77531e0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4467a831fc104eeaa028217b2bd6c727": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a0fda5cfeef4e18b00576b6661f34ed",
              "IPY_MODEL_88b570e477b0461aa895ae042ec2acc8",
              "IPY_MODEL_f9640b65324343e29154feda04019d47"
            ],
            "layout": "IPY_MODEL_94df08720aab44d9b629fefd920f7e4e"
          }
        },
        "45485fae1ab647caa2b1e4a86b9a443d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_485658f399484b999da8ef374dd7e67d",
            "placeholder": "​",
            "style": "IPY_MODEL_40e5da2829654257969c12e77531e0ca",
            "value": " 55.4k/55.4k [00:00&lt;00:00, 1.79MB/s]"
          }
        },
        "455aa9a23e8d45ffa4db195f9ddb0f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45da03f78bf8438cb20551f12eec3522": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "485658f399484b999da8ef374dd7e67d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f85da339afb458086f9136d4ac4d5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf081d786de4e4782e7aec0ea9acdd0",
            "placeholder": "​",
            "style": "IPY_MODEL_3b58ea038cb548c1b87969a958421ae9",
            "value": " 4.98G/4.98G [00:34&lt;00:00, 301MB/s]"
          }
        },
        "512372c439604cb5a1fb652c42ab2313": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c83dd09cba48409a27593ba2b78ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b3efe21f42e44819d3e92642d97d1fb",
              "IPY_MODEL_7a148858398c40cbbf8d0f6f68216acd",
              "IPY_MODEL_978fc7cd005e4d618e4bd5a74957ebaa"
            ],
            "layout": "IPY_MODEL_667c8d288310494f8ae4922559b10c3e"
          }
        },
        "57b3b2f61bc94d28bab74f1b4642fc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57b4ffb228b544739198a06936be68bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_334df13bc642462fab2eb7c4b43608ff",
            "placeholder": "​",
            "style": "IPY_MODEL_dad3edd97f6a4e58a8fab33da8484cbb",
            "value": "model-00002-of-00004.safetensors: 100%"
          }
        },
        "5a3cbf9af6b541ec8e6f77c0b7d75194": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a45097561d74c86b5fd060482fabcf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c55818b0bee4b948f8493110db26306": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6149c16948b14710b51a1992a44ace35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618270ec33354abaad9db39832652874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b3fcb488934fd4a41494655dc80189": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ddc2f01ea840e1bc29d9c1d734b984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6149c16948b14710b51a1992a44ace35",
            "placeholder": "​",
            "style": "IPY_MODEL_6f26bf496ffd41fba6b9df73c715e77f",
            "value": " 855/855 [00:00&lt;00:00, 60.7kB/s]"
          }
        },
        "64e4e4d993674404a94842a5e2bc9e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6d608122a741a785f9dca4a8274ecc",
            "placeholder": "​",
            "style": "IPY_MODEL_196493a56a7b4cd68acb4412e39c42a0",
            "value": " 4/4 [01:31&lt;00:00, 18.97s/it]"
          }
        },
        "6571e0aec12a41e186366e3771caa1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "667c8d288310494f8ae4922559b10c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673a01456a984d4b8be16b76995ebaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb01f9b6aeb44e39ac844d79ebd15204",
            "max": 55351,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e1fed203cdb4af385fe473491ce0d0c",
            "value": 55351
          }
        },
        "674ce8e7227c4e05972e13ceb484c887": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67a49e8fb33b435d9b917b96d0474634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6801c723b9314871ac7f44fd7b5aa5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68bfd77475c2445ba926220299931c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69bebc3000474c39b6ba93fa32bcbe4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccff3c34d3b84370bdfa6c275ff93c88",
            "placeholder": "​",
            "style": "IPY_MODEL_b86f76334b3642369564ad3f3fefad59",
            "value": "config.json: 100%"
          }
        },
        "6b8d0704901e46cf8c8009b0e98ae75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d50c6fd648014aa6aade6954f4b7ce9b",
              "IPY_MODEL_2b5dc1a8b9d34199b82a1509fc8b9de1",
              "IPY_MODEL_24de5aa82b714d12939bf2fa97aa5bed"
            ],
            "layout": "IPY_MODEL_8d1c4e23b65f48eb8268952e34de3f61"
          }
        },
        "6f26bf496ffd41fba6b9df73c715e77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "704669fb0a3b4f90afca6c2185d170e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f84f0f9bcb74f0fb2adeb20d06cd435",
              "IPY_MODEL_2675275f28a8445cae4a3797e71e375e",
              "IPY_MODEL_8dd37d685bbd4f169e2fc78e536e40ab"
            ],
            "layout": "IPY_MODEL_7b180a5104de477a8a5138e22e8b6653"
          }
        },
        "7254a7575c9c4d57a234d1956c5f97da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72bad7767ddd43d08f32ad92598f0801": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a0fda5cfeef4e18b00576b6661f34ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7254a7575c9c4d57a234d1956c5f97da",
            "placeholder": "​",
            "style": "IPY_MODEL_5a45097561d74c86b5fd060482fabcf3",
            "value": "model-00003-of-00004.safetensors: 100%"
          }
        },
        "7a148858398c40cbbf8d0f6f68216acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef02d998f3e4d9ca8415f981534d76e",
            "max": 1168138808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eabb4c45f4e04191808c050eed7683fb",
            "value": 1168138808
          }
        },
        "7b180a5104de477a8a5138e22e8b6653": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b73ab6cda2f441592a7341fb2ae6f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45da03f78bf8438cb20551f12eec3522",
            "placeholder": "​",
            "style": "IPY_MODEL_090811705a994611a7281cb7e23e5157",
            "value": " 296/296 [00:00&lt;00:00, 10.7kB/s]"
          }
        },
        "7b8533cbd4a54da1b7e9a7764bb5f37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa0e89f52c09418cbe31d38d8f1571aa",
              "IPY_MODEL_07563a93f475415193ee74077ed3681e",
              "IPY_MODEL_4f85da339afb458086f9136d4ac4d5e0"
            ],
            "layout": "IPY_MODEL_c774f24af06e4f3e98767e589fca2889"
          }
        },
        "7e9cdd345909478aa06b5ea135b83bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef02d998f3e4d9ca8415f981534d76e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82b0b27542d840caaf07d6da26f82564": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69bebc3000474c39b6ba93fa32bcbe4e",
              "IPY_MODEL_395c6470cf354acda9fc5dcdda05333f",
              "IPY_MODEL_64ddc2f01ea840e1bc29d9c1d734b984"
            ],
            "layout": "IPY_MODEL_e3183a4aa1b64cb89feb5e4b92c159d5"
          }
        },
        "83078e0f247043c2a8bac1a0cc1e0626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84717008302d4dcbaaeb317a06e2244d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4aac58c094400b980a55a21ced3aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_6801c723b9314871ac7f44fd7b5aa5a3",
            "value": "Downloading shards: 100%"
          }
        },
        "88b570e477b0461aa895ae042ec2acc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca00d2e80ebe44329647ecc375bd8070",
            "max": 4915916176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29f519d173ac4918beb0d632bde45bc1",
            "value": 4915916176
          }
        },
        "8a7b53202dfd49d688a09c24753270e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8abee8205c874cb0aab4db5f98463699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d1c4e23b65f48eb8268952e34de3f61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd37d685bbd4f169e2fc78e536e40ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f894a0d9e94d3180e4e496f088c3e2",
            "placeholder": "​",
            "style": "IPY_MODEL_57b3b2f61bc94d28bab74f1b4642fc6b",
            "value": " 4/4 [01:16&lt;00:00, 16.40s/it]"
          }
        },
        "8ed4d05ab7384154b2d3541dfbe96d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf77cdcdb7d04246b65f64445f1e698e",
              "IPY_MODEL_1521bc93d8434043ba07ab76ade23821",
              "IPY_MODEL_7b73ab6cda2f441592a7341fb2ae6f59"
            ],
            "layout": "IPY_MODEL_618270ec33354abaad9db39832652874"
          }
        },
        "926ec72916824af2a6282d86c1fc8ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9289f5ec52ac4fed9aa3b8fda9b80550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6847f804eee43d1816208b9ccaffe93",
            "placeholder": "​",
            "style": "IPY_MODEL_978c81ad0df44d4091329bd548a58042",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "94df08720aab44d9b629fefd920f7e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c5343993f940c5b6883e3ca9443df4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978c81ad0df44d4091329bd548a58042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "978fc7cd005e4d618e4bd5a74957ebaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d82f4826b5440cb5ef392e117044ed",
            "placeholder": "​",
            "style": "IPY_MODEL_c88d67f605c34dcea971051166dea79b",
            "value": " 1.17G/1.17G [00:05&lt;00:00, 179MB/s]"
          }
        },
        "995c7b6122d14add98d661b844917d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1fed203cdb4af385fe473491ce0d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ecdfa95ef104502805b13840d05003e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f398683517c4f59b15748b3fff194cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a43af1b3edea4d0f9e23603d5a0dceab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6847f804eee43d1816208b9ccaffe93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6d608122a741a785f9dca4a8274ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf081d786de4e4782e7aec0ea9acdd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24403fae79f4694bdea1c8d60916219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_362ceaaff6784e2daeb2052d857e60a8",
              "IPY_MODEL_20b272b8fbdd48de9e1744e729279e15",
              "IPY_MODEL_2a92f2020cb2450a9352089fa32dd673"
            ],
            "layout": "IPY_MODEL_40bc3d042386446cbf29f396af98c572"
          }
        },
        "b6f894a0d9e94d3180e4e496f088c3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86f76334b3642369564ad3f3fefad59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c044aca116104afea4d949122e180042": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e49bc773414ab6aee05651673d2064": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c774f24af06e4f3e98767e589fca2889": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88d67f605c34dcea971051166dea79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca00d2e80ebe44329647ecc375bd8070": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccff3c34d3b84370bdfa6c275ff93c88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf77cdcdb7d04246b65f64445f1e698e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7b53202dfd49d688a09c24753270e4",
            "placeholder": "​",
            "style": "IPY_MODEL_17d556116b9a49bfb957497dde86a956",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "cfa6525ffad740e2a61717d8f33ffd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d147a8e4c06c4fc9bf627eb82d33618c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72bad7767ddd43d08f32ad92598f0801",
            "placeholder": "​",
            "style": "IPY_MODEL_30003cc10e5f4a3bbdfae9aa4c336acc",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "d2a3b47628724bff97183936180cfe1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50c6fd648014aa6aade6954f4b7ce9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3cbf9af6b541ec8e6f77c0b7d75194",
            "placeholder": "​",
            "style": "IPY_MODEL_6571e0aec12a41e186366e3771caa1fc",
            "value": "generation_config.json: 100%"
          }
        },
        "d65ae82d524a4643add4c444ce8c16fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c2c34db76a4bc9b74cdce5553d6294",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c55818b0bee4b948f8493110db26306",
            "value": 4
          }
        },
        "dad3edd97f6a4e58a8fab33da8484cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dca004b35c974d27b52399aec64d11d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e02d69ee8d624addb5652fee1bab7182": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07a045b3a5442af895e069b7ffedd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e192116f58a94c15888562d87572035b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3183a4aa1b64cb89feb5e4b92c159d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5991acdb2a84e29b1f7a6f18418a440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5aa7bc32fcc4d5db6b6acf9b69019e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eabb4c45f4e04191808c050eed7683fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb01f9b6aeb44e39ac844d79ebd15204": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed894764fb8e408bbc49b4a7c30f4d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e192116f58a94c15888562d87572035b",
            "placeholder": "​",
            "style": "IPY_MODEL_995c7b6122d14add98d661b844917d74",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "f1f83b0ab9634a718be6d7cd5fbd48e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84717008302d4dcbaaeb317a06e2244d",
              "IPY_MODEL_d65ae82d524a4643add4c444ce8c16fd",
              "IPY_MODEL_64e4e4d993674404a94842a5e2bc9e3f"
            ],
            "layout": "IPY_MODEL_7e9cdd345909478aa06b5ea135b83bd5"
          }
        },
        "f33f64223da14062a645e29c0ff00c95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c2c34db76a4bc9b74cdce5553d6294": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4dfa53cbc3141208d71c7bdb46b15eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f63fd26662cd40c9b98234a732475dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6d12cc4a02a4b7bb2cb9726618e0ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f748db1fdb6b4e9395151414fcd1c4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9289f5ec52ac4fed9aa3b8fda9b80550",
              "IPY_MODEL_673a01456a984d4b8be16b76995ebaac",
              "IPY_MODEL_45485fae1ab647caa2b1e4a86b9a443d"
            ],
            "layout": "IPY_MODEL_64b3fcb488934fd4a41494655dc80189"
          }
        },
        "f7d82f4826b5440cb5ef392e117044ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9640b65324343e29154feda04019d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43af1b3edea4d0f9e23603d5a0dceab",
            "placeholder": "​",
            "style": "IPY_MODEL_83078e0f247043c2a8bac1a0cc1e0626",
            "value": " 4.92G/4.92G [00:25&lt;00:00, 74.8MB/s]"
          }
        },
        "fa0e89f52c09418cbe31d38d8f1571aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_512372c439604cb5a1fb652c42ab2313",
            "placeholder": "​",
            "style": "IPY_MODEL_dca004b35c974d27b52399aec64d11d0",
            "value": "model-00001-of-00004.safetensors: 100%"
          }
        },
        "fbf31927d73a46d7825d3cfebba1b4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4e49bc773414ab6aee05651673d2064",
            "placeholder": "​",
            "style": "IPY_MODEL_2a850d1e7a414bd59a330e8e8e3e8ae9",
            "value": " 5.00G/5.00G [00:24&lt;00:00, 244MB/s]"
          }
        },
        "ff2876b1ad6147e1b46afe0f5bf7f64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d147a8e4c06c4fc9bf627eb82d33618c",
              "IPY_MODEL_2e3b828ab0c14c2abfbad03eb682333f",
              "IPY_MODEL_ed894764fb8e408bbc49b4a7c30f4d51"
            ],
            "layout": "IPY_MODEL_f4dfa53cbc3141208d71c7bdb46b15eb"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}